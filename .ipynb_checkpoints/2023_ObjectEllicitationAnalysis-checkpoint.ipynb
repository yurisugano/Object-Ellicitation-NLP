{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPzjUxA0oi4VL+/Awr4xYPW"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "43fc49e8ed284a70b1a03e487ba1bcfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_72994e47ecf443139877d09b089d7611",
              "IPY_MODEL_fec3d8c30cf74380864ae194f49c1186",
              "IPY_MODEL_02351ce5904e4293aa2eca7dcfe8d507"
            ],
            "layout": "IPY_MODEL_f6efcc65c7f544f2b73c411b9a707c26"
          }
        },
        "72994e47ecf443139877d09b089d7611": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40ec6a7169884b48a19179862755ca5d",
            "placeholder": "​",
            "style": "IPY_MODEL_09b0b61f911d4253a96f904176defe08",
            "value": "Batches: 100%"
          }
        },
        "fec3d8c30cf74380864ae194f49c1186": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f8e79714cc94dd1854215aa29601a95",
            "max": 168,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3609e047444d4c508edd6f78444dd3a9",
            "value": 168
          }
        },
        "02351ce5904e4293aa2eca7dcfe8d507": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17e7ee7101f543a290a93aabe6b693f3",
            "placeholder": "​",
            "style": "IPY_MODEL_4d1a79dce0e24078812a01d8036c4d63",
            "value": " 168/168 [00:02&lt;00:00, 113.33it/s]"
          }
        },
        "f6efcc65c7f544f2b73c411b9a707c26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40ec6a7169884b48a19179862755ca5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09b0b61f911d4253a96f904176defe08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f8e79714cc94dd1854215aa29601a95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3609e047444d4c508edd6f78444dd3a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "17e7ee7101f543a290a93aabe6b693f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d1a79dce0e24078812a01d8036c4d63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18335c42cd65497ead10231a8dfdc224": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0efe405da36d41a9a2ec708e27897a80",
              "IPY_MODEL_0d70eca0615b4d7dba2e17014cc8544a",
              "IPY_MODEL_5dca945d18494e26afe0c3f5145bb09e"
            ],
            "layout": "IPY_MODEL_b4681ce052174635b106c88dd2e7f9d6"
          }
        },
        "0efe405da36d41a9a2ec708e27897a80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21afe3b6251a41d8ae8408400979246c",
            "placeholder": "​",
            "style": "IPY_MODEL_6e25ec3e981b49d886a35206f2da36cf",
            "value": "Batches: 100%"
          }
        },
        "0d70eca0615b4d7dba2e17014cc8544a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc38f95b7f04450f81cbed91b330028f",
            "max": 168,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c9330b6860d64920984692b9efcd3912",
            "value": 168
          }
        },
        "5dca945d18494e26afe0c3f5145bb09e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7eb3abcf18f04241b0f0743ba297cd0e",
            "placeholder": "​",
            "style": "IPY_MODEL_8d2abcb9b12c4555a5e6374c3f7b2fd9",
            "value": " 168/168 [00:06&lt;00:00, 40.28it/s]"
          }
        },
        "b4681ce052174635b106c88dd2e7f9d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21afe3b6251a41d8ae8408400979246c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e25ec3e981b49d886a35206f2da36cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc38f95b7f04450f81cbed91b330028f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9330b6860d64920984692b9efcd3912": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7eb3abcf18f04241b0f0743ba297cd0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d2abcb9b12c4555a5e6374c3f7b2fd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVQiFOCAbqK0"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "!rm -rf ObjectEllicitationNLP\n",
        "!git clone https://github.com/yurisugano/ObjectEllicitationNLP.git\n",
        "!pip install python-docx\n",
        "!pip install nltk\n",
        "!pip install \"git+https://github.com/samwaterbury/rpunct.git\"\n",
        "!pip install bertopic\n",
        "!pip install gensim\n",
        "!pip install collections"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis\n",
        "\n",
        "The notebook is divided into **word token** analysis and **sentence token** analysis.\n",
        "\n",
        "First, load packages and data. To remove inconsistencies with punctuation, all punctuation is removed and all words are turned to lower case."
      ],
      "metadata": {
        "id": "F_E5cZlyab7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary packages\n",
        "import re\n",
        "from docx import Document\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from rpunct import RestorePuncts\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "# Load raw data\n",
        "raw_data = Document('/content/ObjectEllicitationNLP/Transcripts.docx')\n",
        "\n",
        "# Define functions to handle formatting\n",
        "def remove_unwanted_chars(paragraph_text):\n",
        "    \"\"\"\n",
        "    Input: docx paragraph object\n",
        "\n",
        "    Remove all curly braces, square brackets, punctuation and turn all sentences to lower case.\n",
        "\n",
        "    Output: docx paragraph object formatted\n",
        "    \"\"\"\n",
        "    paragraph_text = re.sub(r'[{}\\[\\]]', '', paragraph_text)  # remove curly braces and square brackets\n",
        "    paragraph_text = re.sub(r'[^\\w\\s]', '', paragraph_text)  # remove punctuation\n",
        "    return paragraph_text.lower()\n",
        "\n",
        "\n",
        "# Create data object\n",
        "data = defaultdict(str)\n",
        "\n",
        "# Process paragraphs and return statements\n",
        "for paragraph in raw_data.paragraphs:\n",
        "    # Convert paragraph to string\n",
        "    text = str(paragraph.text)\n",
        "\n",
        "    # Split the paragraph text into subject and statement\n",
        "    split_text = text.split(\": \", 1)\n",
        "    # Verify that subject is a 3 digit number before \":\", otherwise ignore the \":\"\n",
        "    if len(split_text) == 2 and re.match(r'\\{\\d{3}\\}', split_text[0]):\n",
        "        subject, statement = split_text\n",
        "        subject = subject[1:-1]\n",
        "\n",
        "        # Concatenate statements for the same subject\n",
        "        data[subject] += remove_unwanted_chars(statement)"
      ],
      "metadata": {
        "id": "_B0Y-af9ZDA5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, some summaries:"
      ],
      "metadata": {
        "id": "R1inKLa0iCjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of subjects: {len(data.keys())}\")\n",
        "\n",
        "\n",
        "for subject, statements in data.items():\n",
        "    print(f\"{subject}: {len(statements)} words.\")\n",
        "    # Add the sentences to a dictionary entry\n",
        "\n",
        "    data[subject] = {'statements': statements}\n",
        "\n",
        "\n",
        "# Delete the interviewer\n",
        "del data['000']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1w24YNmtiG_q",
        "outputId": "449fed20-7615-46e5-c244-e0f5049e2128"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of subjects: 33\n",
            "000: 55747 words.\n",
            "104: 9640 words.\n",
            "105: 15819 words.\n",
            "106: 7681 words.\n",
            "107: 12764 words.\n",
            "108: 9558 words.\n",
            "109: 12522 words.\n",
            "110: 11473 words.\n",
            "111: 14912 words.\n",
            "112: 20789 words.\n",
            "113: 6861 words.\n",
            "114: 4754 words.\n",
            "115: 8979 words.\n",
            "116: 4892 words.\n",
            "117: 7354 words.\n",
            "118: 7364 words.\n",
            "119: 6964 words.\n",
            "120: 7701 words.\n",
            "221: 320 words.\n",
            "121: 4930 words.\n",
            "122: 8776 words.\n",
            "123: 4812 words.\n",
            "124: 6849 words.\n",
            "126: 9737 words.\n",
            "127: 7428 words.\n",
            "128: 23008 words.\n",
            "130: 12011 words.\n",
            "131: 15055 words.\n",
            "132: 19491 words.\n",
            "133: 8828 words.\n",
            "134: 8678 words.\n",
            "135: 15104 words.\n",
            "136: 9251 words.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysis with word tokens\n",
        "\n",
        "Input: a string with all the statements by the subject.\n",
        "\n",
        "\n",
        "### Pre-processing pipeline\n",
        "\n",
        "1. Remove punctuation\n",
        "2. Case-folding\n",
        "3. Tokenization\n",
        "4. Lemmatization\n",
        "5. Stop-word removal\n",
        "6. Disfluency removal\n",
        "\n",
        "### Analysis:\n",
        "1. Most frequent words per corpus\n",
        "2. Most frequent words per subject\n",
        "3. LDA vs BERTopic for topic modeling\n"
      ],
      "metadata": {
        "id": "W4rHDUSlZdrv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('words')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def track_made_up_words(text):\n",
        "    # List of common English words\n",
        "    english_words = set(w.lower() for w in nltk.corpus.words.words())\n",
        "\n",
        "    # Find made-up words\n",
        "    made_up_words = [word for word in text if word not in english_words]\n",
        "    return made_up_words\n",
        "\n",
        "def process_text(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]  # lemmatize words\n",
        "    tokens = [token for token in tokens if token not in stop_words]  # remove stop words\n",
        "    tokens = [token for token in tokens if token not in ['uh', 'um']]  # remove disfluencies\n",
        "    return tokens\n",
        "\n",
        "# Process each subject's statements\n",
        "for subject, subject_data in data.items():\n",
        "    subject_data['tokens'] = process_text(subject_data['statements'])\n",
        "    subject_data['made_up_words'] = track_made_up_words(subject_data['tokens'])"
      ],
      "metadata": {
        "id": "nVrw3OPoZdBt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e0329d2-cff7-492e-f8ce-4b4ec93b7578"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['107']['made_up_words'][:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "4MYpwl4opraS",
        "outputId": "6921093a-19b6-4d79-88d5-d70bc5672ab3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a47881811d9b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'107'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'made_up_words'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from gensim import corpora, models\n",
        "from bertopic import BERTopic\n",
        "import numpy as np\n",
        "\n",
        "# Define the number of most frequent words to return\n",
        "n = 10\n",
        "\n",
        "# Extract all tokens from each subject and create a single object 'all_tokens'\n",
        "all_tokens = [token for subject in data.values() for token in subject['tokens']]\n",
        "\n",
        "# Get the top n most frequent words for the entire document\n",
        "counter = Counter(all_tokens)\n",
        "print(counter.most_common(n))\n",
        "\n",
        "# Get the top n most frequent words for each subject\n",
        "for subject, info in data.items():\n",
        "    counter = Counter(info['tokens'])\n",
        "    print(f\"Subject: {subject}, Top {n} words: {counter.most_common(n)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvS7tTXzrP_V",
        "outputId": "cb390ace-a9ec-4ea8-ed47-31ca1b3f4cd5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('like', 3429), ('one', 1022), ('kind', 579), ('feel', 478), ('dont', 404), ('think', 386), ('yeah', 375), ('know', 365), ('ha', 323), ('little', 310)]\n",
            "Subject: 104, Top 10 words: [('like', 102), ('feel', 52), ('one', 35), ('kind', 24), ('smooth', 16), ('soft', 16), ('little', 14), ('rough', 12), ('also', 11), ('really', 11)]\n",
            "Subject: 105, Top 10 words: [('like', 343), ('kind', 46), ('yeah', 29), ('feel', 27), ('one', 25), ('know', 22), ('ha', 22), ('dont', 21), ('thing', 18), ('maybe', 18)]\n",
            "Subject: 106, Top 10 words: [('like', 121), ('guess', 25), ('think', 23), ('yeah', 22), ('one', 21), ('feel', 16), ('dont', 14), ('know', 11), ('218', 10), ('two', 9)]\n",
            "Subject: 107, Top 10 words: [('like', 115), ('one', 57), ('kind', 45), ('feel', 26), ('would', 20), ('dont', 18), ('thing', 17), ('im', 14), ('side', 14), ('ha', 13)]\n",
            "Subject: 108, Top 10 words: [('like', 77), ('one', 65), ('ha', 26), ('yeah', 18), ('side', 18), ('kind', 17), ('silver', 16), ('thats', 14), ('little', 12), ('gold', 11)]\n",
            "Subject: 109, Top 10 words: [('like', 255), ('one', 72), ('feel', 47), ('kind', 35), ('guess', 27), ('probably', 21), ('dont', 21), ('could', 19), ('stuff', 18), ('really', 18)]\n",
            "Subject: 110, Top 10 words: [('like', 159), ('one', 30), ('feel', 26), ('yeah', 18), ('thats', 16), ('know', 15), ('fabric', 15), ('dont', 14), ('theyre', 10), ('two', 10)]\n",
            "Subject: 111, Top 10 words: [('like', 204), ('seems', 38), ('dont', 33), ('pretty', 32), ('lot', 26), ('object', 25), ('yeah', 23), ('kind', 21), ('know', 20), ('nice', 17)]\n",
            "Subject: 112, Top 10 words: [('like', 168), ('one', 71), ('ha', 28), ('ok', 24), ('actually', 22), ('two', 22), ('kind', 21), ('look', 20), ('theyre', 20), ('thats', 19)]\n",
            "Subject: 113, Top 10 words: [('like', 99), ('kind', 19), ('different', 15), ('little', 13), ('yeah', 12), ('color', 12), ('look', 9), ('ha', 9), ('ok', 8), ('touch', 8)]\n",
            "Subject: 114, Top 10 words: [('like', 113), ('think', 15), ('ok', 13), ('might', 9), ('yeah', 8), ('one', 7), ('dont', 7), ('color', 7), ('know', 6), ('thats', 6)]\n",
            "Subject: 115, Top 10 words: [('like', 56), ('one', 47), ('feel', 24), ('kind', 22), ('ha', 15), ('wa', 13), ('different', 13), ('little', 12), ('really', 11), ('yeah', 10)]\n",
            "Subject: 116, Top 10 words: [('like', 64), ('one', 21), ('think', 14), ('thing', 14), ('kind', 13), ('yeah', 10), ('thats', 8), ('know', 7), ('would', 7), ('guess', 6)]\n",
            "Subject: 117, Top 10 words: [('one', 46), ('like', 41), ('oh', 20), ('think', 20), ('color', 16), ('211', 14), ('215', 14), ('thing', 13), ('216', 12), ('213', 12)]\n",
            "Subject: 118, Top 10 words: [('like', 31), ('one', 23), ('sort', 16), ('say', 15), ('material', 13), ('ha', 11), ('would', 11), ('made', 10), ('202', 9), ('different', 9)]\n",
            "Subject: 119, Top 10 words: [('like', 55), ('color', 22), ('look', 20), ('thats', 16), ('make', 12), ('dont', 11), ('204', 10), ('reminds', 10), ('put', 9), ('gorilla', 8)]\n",
            "Subject: 120, Top 10 words: [('like', 48), ('know', 31), ('thats', 21), ('something', 17), ('dont', 13), ('im', 12), ('could', 12), ('201', 11), ('use', 11), ('make', 10)]\n",
            "Subject: 221, Top 10 words: [('everything', 4), ('different', 3), ('table', 2), ('thats', 2), ('know', 2), ('notice', 1), ('yeah', 1), ('put', 1), ('nothing', 1), ('matter', 1)]\n",
            "Subject: 121, Top 10 words: [('one', 14), ('like', 12), ('type', 11), ('material', 11), ('different', 10), ('think', 10), ('thats', 9), ('ball', 8), ('im', 8), ('square', 8)]\n",
            "Subject: 122, Top 10 words: [('like', 73), ('similar', 21), ('two', 15), ('think', 15), ('one', 14), ('something', 12), ('would', 11), ('term', 10), ('218', 10), ('ha', 9)]\n",
            "Subject: 123, Top 10 words: [('one', 14), ('shape', 13), ('like', 12), ('also', 10), ('different', 9), ('201', 9), ('203', 9), ('202', 9), ('similar', 9), ('little', 8)]\n",
            "Subject: 124, Top 10 words: [('like', 73), ('kind', 27), ('thing', 14), ('one', 13), ('yeah', 13), ('would', 12), ('little', 12), ('think', 11), ('fabric', 10), ('use', 9)]\n",
            "Subject: 126, Top 10 words: [('like', 209), ('one', 35), ('feel', 34), ('yeah', 29), ('kind', 28), ('color', 22), ('really', 18), ('set', 15), ('also', 13), ('two', 11)]\n",
            "Subject: 127, Top 10 words: [('like', 46), ('one', 32), ('dont', 25), ('know', 19), ('kind', 15), ('also', 11), ('yeah', 11), ('think', 10), ('soft', 10), ('wa', 9)]\n",
            "Subject: 128, Top 10 words: [('like', 235), ('think', 43), ('one', 32), ('dont', 30), ('ha', 30), ('kind', 27), ('theyre', 26), ('would', 26), ('know', 25), ('look', 25)]\n",
            "Subject: 130, Top 10 words: [('like', 98), ('one', 30), ('look', 18), ('think', 16), ('color', 14), ('theyre', 13), ('fabric', 13), ('feel', 10), ('also', 10), ('thing', 10)]\n",
            "Subject: 131, Top 10 words: [('like', 179), ('one', 56), ('yeah', 39), ('feel', 25), ('think', 23), ('know', 22), ('would', 21), ('211', 21), ('dont', 19), ('thats', 18)]\n",
            "Subject: 132, Top 10 words: [('like', 213), ('dont', 47), ('think', 43), ('know', 42), ('one', 41), ('kind', 33), ('color', 28), ('yeah', 27), ('feel', 26), ('also', 24)]\n",
            "Subject: 133, Top 10 words: [('like', 115), ('one', 48), ('feel', 42), ('yeah', 22), ('kind', 18), ('almost', 16), ('224', 15), ('pretty', 11), ('211', 11), ('219', 11)]\n",
            "Subject: 134, Top 10 words: [('one', 29), ('ha', 26), ('like', 21), ('kind', 12), ('220', 12), ('217', 11), ('red', 10), ('ok', 10), ('think', 10), ('feel', 9)]\n",
            "Subject: 135, Top 10 words: [('kind', 100), ('one', 85), ('like', 71), ('theyre', 60), ('different', 47), ('little', 38), ('got', 27), ('maybe', 25), ('ha', 24), ('thing', 22)]\n",
            "Subject: 136, Top 10 words: [('one', 24), ('like', 21), ('feel', 16), ('would', 14), ('interesting', 14), ('different', 13), ('think', 11), ('also', 11), ('color', 11), ('211', 11)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Perform LDA\n",
        "dictionary = corpora.Dictionary([info['tokens'] for info in data.values()])\n",
        "corpus = [dictionary.doc2bow(info['tokens']) for info in data.values()]\n",
        "lda_model = models.LdaModel(corpus, num_topics=10, id2word=dictionary, passes=2)\n",
        "lda_topics = lda_model.print_topics(num_words=5)\n",
        "print(lda_topics)\n",
        "\n",
        "# Perform BERTopic\n",
        "topic_model = BERTopic(language=\"english\", calculate_probabilities=True, verbose=True)\n",
        "topics, probs = topic_model.fit_transform(all_tokens)\n",
        "topic_freq = topic_model.get_topic_freq()\n",
        "print(topic_freq)\n"
      ],
      "metadata": {
        "id": "dK6hLMx9rowC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysis with sentence tokens\n",
        "\n",
        "Input: a string with all the stat"
      ],
      "metadata": {
        "id": "OtbnbL5_aNsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "# Step 7: Restore punctuation and capitalize words, then tokenize sentences\n",
        "rpunct = RestorePuncts()"
      ],
      "metadata": {
        "id": "W_EZV-fpaNCa"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for subject, subject_data in data.items():\n",
        "    punctuated_text = rpunct.punctuate(subject_data['statements'])\n",
        "    subject_data['sentence-tokens'] = sent_tokenize(punctuated_text)"
      ],
      "metadata": {
        "id": "BxAsL0abuP1e"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data['105']['sentence-tokens'][:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrHHItmFt2Ih",
        "outputId": "a9946b34-6032-4a76-e508-f834cbbac0d1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Ok is my bag and stuff Ok. throws 203 at the wall and it falls off.', 'Ok so its like sticks to like hard surfaces and like I said not always the best.', 'but when I was a kid and I would play with them and I was alwaysi would always like to do this rolls ball on table so it sticks and unsticks.', 'It makes popping sound and like make popcorn noises.', 'So its also different colors red, blue and green.', 'My hair is in it now its ok but this is cool too.', 'Its also a sphere but in like a subtle way because the middle is like a hard little circle and then this forms a circle.', 'But its like all these little things Ok ooh this 202 reminds me of like a pencil eraser almost just in the way it looks and like the way it feels.', 'Im not super familiar with a bouncy ball like this, its kind of like softer than a normal bouncy ball.', 'like I feel like if this hit me it like wouldnt hurt as much.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bertopic import BERTopic\n",
        "from umap import UMAP\n",
        "from hdbscan import HDBSCAN\n",
        "\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Extract all tokens from each subject and create a single object 'all_tokens'\n",
        "sentence_tokens = [token for subject in data.values() for token in subject['sentence-tokens']]\n",
        "\n",
        "# Pre-calculate embeddings\n",
        "embedding_allMini = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "embeddings_allMini = embedding_allMini.encode(sentence_tokens, show_progress_bar=True)\n",
        "\n",
        "embedding_roberta = SentenceTransformer(\"roberta-base-nli-mean-tokens\")\n",
        "embeddings_roberta = embedding_roberta.encode(sentence_tokens, show_progress_bar=True)\n",
        "\n",
        "# Define models\n",
        "umap_model = UMAP(n_neighbors=8, n_components=10, min_dist=0.0, metric='cosine', random_state=42)\n",
        "hdbscan_model = HDBSCAN(min_cluster_size=10, cluster_selection_epsilon=0.05, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
        "\n",
        "# Improve topic representation\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer_model = CountVectorizer(stop_words=\"english\", min_df=2, ngram_range=(1, 2))\n",
        "\n",
        "topic_model = BERTopic(\n",
        "  # Pipeline models\n",
        "  embedding_model=embedding_allMini,\n",
        "  umap_model=umap_model,\n",
        "  hdbscan_model=hdbscan_model,\n",
        "  vectorizer_model=vectorizer_model,\n",
        "\n",
        "  # Hyperparameters\n",
        "  top_n_words=5,\n",
        "  verbose=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "iis4S2XIZDK4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "43fc49e8ed284a70b1a03e487ba1bcfe",
            "72994e47ecf443139877d09b089d7611",
            "fec3d8c30cf74380864ae194f49c1186",
            "02351ce5904e4293aa2eca7dcfe8d507",
            "f6efcc65c7f544f2b73c411b9a707c26",
            "40ec6a7169884b48a19179862755ca5d",
            "09b0b61f911d4253a96f904176defe08",
            "2f8e79714cc94dd1854215aa29601a95",
            "3609e047444d4c508edd6f78444dd3a9",
            "17e7ee7101f543a290a93aabe6b693f3",
            "4d1a79dce0e24078812a01d8036c4d63",
            "18335c42cd65497ead10231a8dfdc224",
            "0efe405da36d41a9a2ec708e27897a80",
            "0d70eca0615b4d7dba2e17014cc8544a",
            "5dca945d18494e26afe0c3f5145bb09e",
            "b4681ce052174635b106c88dd2e7f9d6",
            "21afe3b6251a41d8ae8408400979246c",
            "6e25ec3e981b49d886a35206f2da36cf",
            "dc38f95b7f04450f81cbed91b330028f",
            "c9330b6860d64920984692b9efcd3912",
            "7eb3abcf18f04241b0f0743ba297cd0e",
            "8d2abcb9b12c4555a5e6374c3f7b2fd9"
          ]
        },
        "outputId": "80cb8f65-94ed-4d7a-e34d-9f5111cb12d9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/168 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43fc49e8ed284a70b1a03e487ba1bcfe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/168 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "18335c42cd65497ead10231a8dfdc224"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topics, probs = topic_model.fit_transform(sentence_tokens, embeddings_allMini)\n",
        "# topics_roberta, probs_roberta = topic_model.fit_transform(sentence_tokens, embeddings_roberta)\n"
      ],
      "metadata": {
        "id": "ZCxhySERZDOe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "b45c3f5e-4019-4376-e49b-e9c3996ed412"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-07-18 16:45:16,279 - BERTopic - Reduced dimensionality\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bertopic/_bertopic.py\u001b[0m in \u001b[0;36m_cluster_embeddings\u001b[0;34m(self, umap_embeddings, documents, partial_fit, y)\u001b[0m\n\u001b[1;32m   3217\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3218\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhdbscan_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mumap_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3219\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hdbscan/hdbscan_.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1204\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_min_spanning_tree\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1205\u001b[0;31m         ) = hdbscan(clean_data, **kwargs)\n\u001b[0m\u001b[1;32m   1206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hdbscan/hdbscan_.py\u001b[0m in \u001b[0;36mhdbscan\u001b[0;34m(X, min_cluster_size, min_samples, alpha, cluster_selection_epsilon, max_cluster_size, metric, p, leaf_size, algorithm, memory, approx_min_span_tree, gen_min_span_tree, core_dist_n_jobs, cluster_selection_method, allow_single_cluster, match_reference_implementation, **kwargs)\u001b[0m\n\u001b[1;32m    883\u001b[0m     return (\n\u001b[0;32m--> 884\u001b[0;31m         _tree_to_labels(\n\u001b[0m\u001b[1;32m    885\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hdbscan/hdbscan_.py\u001b[0m in \u001b[0;36m_tree_to_labels\u001b[0;34m(X, single_linkage_tree, min_cluster_size, cluster_selection_method, allow_single_cluster, match_reference_implementation, cluster_selection_epsilon, max_cluster_size)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \"\"\"\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mcondensed_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcondense_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle_linkage_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_cluster_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0mstability_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_stability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondensed_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mhdbscan/_hdbscan_tree.pyx\u001b[0m in \u001b[0;36mhdbscan._hdbscan_tree.condense_tree\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mhdbscan/_hdbscan_tree.pyx\u001b[0m in \u001b[0;36mhdbscan._hdbscan_tree.condense_tree\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object cannot be interpreted as an integer",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-289468fd22a3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtopics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopic_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings_allMini\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# topics_roberta, probs_roberta = topic_model.fit_transform(sentence_tokens, embeddings_roberta)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bertopic/_bertopic.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, documents, embeddings, images, y)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;31m# Cluster reduced embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cluster_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mumap_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;31m# Sort and Map Topic IDs by their frequency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bertopic/_bertopic.py\u001b[0m in \u001b[0;36m_cluster_embeddings\u001b[0;34m(self, umap_embeddings, documents, partial_fit, y)\u001b[0m\n\u001b[1;32m   3218\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhdbscan_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mumap_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3219\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3220\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhdbscan_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mumap_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3222\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hdbscan/hdbscan_.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1203\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_single_linkage_tree\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_min_spanning_tree\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1205\u001b[0;31m         ) = hdbscan(clean_data, **kwargs)\n\u001b[0m\u001b[1;32m   1206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"precomputed\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hdbscan/hdbscan_.py\u001b[0m in \u001b[0;36mhdbscan\u001b[0;34m(X, min_cluster_size, min_samples, alpha, cluster_selection_epsilon, max_cluster_size, metric, p, leaf_size, algorithm, memory, approx_min_span_tree, gen_min_span_tree, core_dist_n_jobs, cluster_selection_method, allow_single_cluster, match_reference_implementation, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m     return (\n\u001b[0;32m--> 884\u001b[0;31m         _tree_to_labels(\n\u001b[0m\u001b[1;32m    885\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m             \u001b[0msingle_linkage_tree\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hdbscan/hdbscan_.py\u001b[0m in \u001b[0;36m_tree_to_labels\u001b[0;34m(X, single_linkage_tree, min_cluster_size, cluster_selection_method, allow_single_cluster, match_reference_implementation, cluster_selection_epsilon, max_cluster_size)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mset\u001b[0m \u001b[0mof\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mprobabilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \"\"\"\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mcondensed_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcondense_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle_linkage_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_cluster_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0mstability_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_stability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondensed_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     labels, probabilities, stabilities = get_clusters(\n",
            "\u001b[0;32mhdbscan/_hdbscan_tree.pyx\u001b[0m in \u001b[0;36mhdbscan._hdbscan_tree.condense_tree\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mhdbscan/_hdbscan_tree.pyx\u001b[0m in \u001b[0;36mhdbscan._hdbscan_tree.condense_tree\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object cannot be interpreted as an integer"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topics_"
      ],
      "metadata": {
        "id": "AhYSNDndZDRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xrsskztzZDUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KPYyRkzfZDXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2pBfWwuvZDZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "from docx import Document\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "\n",
        "raw_data = Document('/content/ObjectEllicitationNLP/Transcripts.docx')\n",
        "\n",
        "def add_curly_braces(paragraph_text):\n",
        "    \"\"\"Add curly braces to three-digit numbers not surrounded by square brackets or curly braces.\"\"\"\n",
        "    numbers = re.findall(r'(?<![\\[{])\\b(\\d{3})\\b(?![\\]}])', paragraph_text)\n",
        "    for number in numbers:\n",
        "        transformed_number = '{' + number + '}'\n",
        "        paragraph_text = re.sub(r'\\b' + number + r'\\b', transformed_number, paragraph_text)\n",
        "    return paragraph_text\n",
        "\n",
        "def handle_square_brackets(paragraph_text):\n",
        "    \"\"\"Handle numbers inside square brackets with optional spaces and dashes.\"\"\"\n",
        "    matches = re.findall(r'\\[([\\d\\s,-]+)\\]', paragraph_text)\n",
        "    for match in matches:\n",
        "        numbers = []\n",
        "        for num_range in re.split(r',\\s*|\\s+', match):\n",
        "            num_range = num_range.strip()\n",
        "            if '-' in num_range:\n",
        "                start, end = num_range.split('-')\n",
        "                numbers.extend(range(int(start), int(end) + 1))\n",
        "            else:\n",
        "                numbers.append(int(num_range))\n",
        "\n",
        "        transformed = '[' + ']['.join(map(str, numbers)) + ']'\n",
        "        paragraph_text = paragraph_text.replace('[' + match + ']', transformed)\n",
        "    return paragraph_text\n",
        "\n",
        "for each_paragraph in raw_data.paragraphs:\n",
        "    each_paragraph.text = add_curly_braces(each_paragraph.text)\n",
        "    each_paragraph.text = handle_square_brackets(each_paragraph.text)\n",
        "\n",
        "def extract_info(paragraph_text):\n",
        "    \"\"\"Extract speaker and sentences from a paragraph text.\"\"\"\n",
        "    speaker_match = re.search(r'\\{(\\d{3})\\}', paragraph_text)\n",
        "    sentence_match = re.search(r': (.*)', paragraph_text)\n",
        "\n",
        "    if speaker_match and sentence_match:\n",
        "        speaker = speaker_match.group(1)\n",
        "        sentence = sentence_match.group(1)\n",
        "        return speaker, sentence\n",
        "    else:\n",
        "        return None, None\n",
        "\n",
        "\n",
        "def update_data(data, speaker, sentence):\n",
        "    \"\"\"Update data dictionary with extracted speaker, sentence.\"\"\"\n",
        "    if speaker:\n",
        "        if speaker in data:\n",
        "            data[speaker]['statements'] = ''.join(data[speaker]['statements']) + sentence\n",
        "\n",
        "        else:\n",
        "            data[speaker] = {'statements': [statement]}\n",
        "\n",
        "data = {}\n",
        "\n",
        "for each_paragraph in raw_data.paragraphs:\n",
        "    speaker, statement = extract_info(each_paragraph.text)\n",
        "    update_data(data, speaker, statement)\n",
        "\n",
        "del data['000']"
      ],
      "metadata": {
        "id": "rcjm37iWeTM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_disfluencies(text):\n",
        "    # List of common disfluencies\n",
        "    disfluencies = ['uh', 'um', 'like', 'you know', 'so', 'actually', 'basically', 'seriously', 'literally']\n",
        "\n",
        "    # Tokenize the text\n",
        "    words = word_tokenize(text)\n",
        "\n",
        "    # Remove disfluencies\n",
        "    words = [word for word in words if word not in disfluencies]\n",
        "\n",
        "    return ' '.join(words)\n",
        "\n",
        "\n",
        "def remove_capitalization_and_punctuation(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    return text\n",
        "\n",
        "def add_capitalization_and_punctuation(text):\n",
        "    tokenizer = T5Tokenizer.from_pretrained('SJ-Ray/Re-Punctuate')\n",
        "    model = TFT5ForConditionalGeneration.from_pretrained('SJ-Ray/Re-Punctuate')\n",
        "\n",
        "    inputs = tokenizer.encode(\"punctuate: \" + text, return_tensors=\"tf\")\n",
        "    result = model.generate(inputs)\n",
        "    decoded_output = tokenizer.decode(result[0], skip_special_tokens=True)\n",
        "\n",
        "    return(decoded_output)\n"
      ],
      "metadata": {
        "id": "nnCOFUxdBwyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('words')\n",
        "\n",
        "for subject, subject_data in data.items():\n",
        "    text = subject_data['statements']\n",
        "    made_up_words = track_made_up_words(text, subject)\n",
        "    text = handle_disfluencies(text)\n",
        "    text = remove_capitalization_and_punctuation(text)\n",
        "    text = add_capitalization_and_punctuation(text)\n",
        "\n",
        "    subject_data['statements'] = text\n",
        "    subject_data['made-up-words'] = made_up_words\n",
        "\n",
        "data\n"
      ],
      "metadata": {
        "id": "hwg_3FtjV0dI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LDA\n",
        "\n"
      ],
      "metadata": {
        "id": "qoAKbQI0Tvd9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j_hy2U8qTxfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "from transformers import T5Tokenizer, TFT5ForConditionalGeneration\n"
      ],
      "metadata": {
        "id": "kPNBGbd7efRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qdgu52sbB3JF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "sent_tokenize(\"this is a sentence and this might be another one however I dont know why not maybe i still want to go to the mall yesterday i don't think i tried\")\n"
      ],
      "metadata": {
        "id": "TCKyrrlg5JBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "id": "ageErGW1lbYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "def get_bert_input(data):\n",
        "    input = []\n",
        "    for subject, subject_data in data.items():\n",
        "        statement = subject_data[\"statements\"]\n",
        "        statement_id = []\n",
        "\n",
        "        for sentence in statement:\n",
        "            statement_id.append(f\"{subject} {sentence}\")\n",
        "\n",
        "        sentence_tokens = [sentence for statement in statement for sentence in sent_tokenize(statement)]\n",
        "        input.extend(sentence_tokens)\n",
        "    return(input)\n",
        "\n",
        "docs = get_bert_input(data)\n"
      ],
      "metadata": {
        "id": "o6MvadNtec7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8b9p8dBRhzuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Pre-calculate embeddings\n",
        "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "embeddings = embedding_model.encode(docs, show_progress_bar=True)"
      ],
      "metadata": {
        "id": "_hDpj960eeD1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
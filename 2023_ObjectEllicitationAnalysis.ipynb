{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOWpHG8jUiIrzn8gibx3e6y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yurisugano/ObjectEllicitationNLP/blob/main/2023_ObjectEllicitationAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 1: Data Cleaning\n",
        "\n",
        "First, we will read the `Transcripts.docx`, make necessary changes, and save as a new file.\n",
        "\n",
        "1. Read the `.docx` file into a `doc` object.\n",
        "2. Each paragraph in the `doc` object corresponds to one sentence stated by a subject\n",
        "3. We need to format so all subject and object notation is consistent:\n",
        "  - Enclose all three digit numbers that are not enclosed in curly braces\n",
        "  - Remove spaces and dashes\n",
        "\n",
        "---\n",
        "ℹ️ Packages are aggregates of objects and functions that are used all the time, so they are organized and distributed so others can use. For instance, we imported some packages with `import`. To some of them, we gave them nicknames to make typing easier, so `pandas` can be accessed with `pd`. From other packages we only needed a single function, so we only load that. We used the `Document` function from the `docx` package which can read a `.docx` document. All other package will be explained as they are used.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "QAQcL5-C27Mh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load necessary packages\n",
        "!pip install docx\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import json\n",
        "import nltk\n",
        "from docx import Document\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "# Read the transcript from the cloud\n",
        "doc = Document('/content/drive/My Drive/ObjElc Collab/Transcripts.docx')\n",
        "\n",
        "\n",
        "# Loop over each paragraph in the document\n",
        "for each_paragraph in doc.paragraphs:\n",
        "\n",
        "    # Use regex to find three-digit numbers not surrounded by square brackets or curly braces\n",
        "    numbers = re.findall(r'(?<![\\[{])\\b(\\d{3})\\b(?![\\]}])', each_paragraph.text)\n",
        "\n",
        "    # Iterate over the numbers and add curly braces\n",
        "    for number in numbers:\n",
        "        transformed_number = '{' + number + '}'\n",
        "        each_paragraph.text = re.sub(r'\\b' + number + r'\\b',\n",
        "                                     transformed_number, each_paragraph.text)\n",
        "\n",
        "\n",
        "    # Use regex to find numbers inside square brackets with optional spaces and dashes\n",
        "    matches = re.findall(r'\\[([\\d\\s,-]+)\\]', each_paragraph.text)\n",
        "\n",
        "    # Iterate over the matches\n",
        "    for match in matches:\n",
        "\n",
        "        # Split the matched numbers by comma or space and handle ranges indicated by dashes\n",
        "        numbers = []\n",
        "        for num_range in re.split(r',\\s*|\\s+', match):\n",
        "            num_range = num_range.strip()\n",
        "            if '-' in num_range:\n",
        "                start, end = num_range.split('-')\n",
        "                numbers.extend(range(int(start), int(end) + 1))\n",
        "            else:\n",
        "                numbers.append(int(num_range))\n",
        "\n",
        "        # Construct the transformed string\n",
        "        transformed = '[' + ']['.join(map(str, numbers)) + ']'\n",
        "\n",
        "        # Replace the original match with the transformed string\n",
        "        each_paragraph.text = each_paragraph.text.replace('[' + match + ']', transformed)"
      ],
      "metadata": {
        "id": "ocIAqJkg3bvk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "e0e91965-1792-4c0c-8c15-a78f53551aeb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "PackageNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPackageNotFoundError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-dfed5b0fc01d>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Read the transcript from the cloud\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDocument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/ObjElc Collab/Transcripts.docx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/docx/api.py\u001b[0m in \u001b[0;36mDocument\u001b[0;34m(docx)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \"\"\"\n\u001b[1;32m     24\u001b[0m     \u001b[0mdocx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_default_docx_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdocx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdocx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mdocument_part\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_document_part\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdocument_part\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent_type\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWML_DOCUMENT_MAIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mtmpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"file '%s' is not a Word file, content type is '%s'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/docx/opc/package.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(cls, pkg_file)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0mpkg_file\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \"\"\"\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mpkg_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackageReader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkg_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0mpackage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mUnmarshaller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munmarshal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkg_reader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPartFactory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/docx/opc/pkgreader.py\u001b[0m in \u001b[0;36mfrom_file\u001b[0;34m(pkg_file)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mReturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m|\u001b[0m\u001b[0mPackageReader\u001b[0m\u001b[0;34m|\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mcontents\u001b[0m \u001b[0mof\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mpkg_file\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \"\"\"\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mphys_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPhysPkgReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkg_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mcontent_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ContentTypeMap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_xml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphys_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent_types_xml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mpkg_srels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackageReader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_srels_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphys_reader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPACKAGE_URI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/docx/opc/phys_pkg.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, pkg_file)\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0mreader_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ZipPkgReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                 raise PackageNotFoundError(\n\u001b[0m\u001b[1;32m     31\u001b[0m                     \u001b[0;34m\"Package not found at '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpkg_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 )\n",
            "\u001b[0;31mPackageNotFoundError\u001b[0m: Package not found at '/content/drive/My Drive/ObjElc Collab/Transcripts.docx'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 2: Extracting Subjects and Sentences\n",
        "\n",
        "Here, we go through each paragraph and identify the subject, the sentence, and the objects that are referred to\n",
        "\n",
        "1. We will loop through each paragraph again, now extracting\n",
        "  - `speaker` with all three digit numbers surrounded by `{ }`\n",
        "  - `sentence` for the entire string after `:`\n",
        "  - `objects` for all three digit numbers surrounded by `[ ]`\n",
        "\n",
        "2. Then we take all sentences by the same speaker and concatenate them in a single string.\n",
        "3. Lastly, we create a Pandas data frame named `sentence_data`.\n",
        "  - In order to make each speaker a row and `speaker`, `sentence` and `objects` as columns, we transpose the data frame with `.T`.\n",
        "\n",
        "4. When you want to inspect the data, you can use the function `head()`, which display the first few rows.\n",
        "\n",
        "---\n",
        "ℹ️ A dictionary is an object, a way to store data. We are most familiar with data frames (a format similar to Excel, where each row is an observation and each column is a variable), so we will use data frames to deal with the data, but dictionaries have their own benefits.\n",
        "\n",
        "In Python, the package Pandas is a particular good way to deal with data frames (here accessed with `pd`).\n",
        "\n",
        "The `.` notation is confusing. `head()` is a method, which you can think of as a function that an object can perform. Thus the syntax `sentence_data.head()` means \"from the object `sentence_data`, perform the function `head()`.\" Similarly, above, from the object `pd.DataFrame(data)`, we performed the function `.T`\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "dU4wbQnS29gp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty dictionary to store the data\n",
        "data = {}\n",
        "\n",
        "# Loop over each paragraph in the document\n",
        "for each_paragraph in doc.paragraphs:\n",
        "    # Use regex to extract the speaker, the object, and the sentence\n",
        "    speaker_match = re.search(r'\\{(\\d{3})\\}', each_paragraph.text)\n",
        "    sentence_match = re.search(r': (.*)', each_paragraph.text)\n",
        "    objects_match = re.findall(r'\\[(\\d{3})\\]', each_paragraph.text)\n",
        "\n",
        "    if speaker_match and sentence_match:\n",
        "        speaker = speaker_match.group(1)\n",
        "        sentence = sentence_match.group(1)\n",
        "        objects = objects_match\n",
        "\n",
        "        # Concatenate sentences for each speaker\n",
        "        if speaker in data:\n",
        "            data[speaker]['sentence'] += ' ' + sentence\n",
        "        else:\n",
        "            data[speaker] = {'speaker': speaker,\n",
        "                             'sentence': sentence,\n",
        "                             'objects': objects}\n",
        "\n",
        "sentence_data = pd.DataFrame(data).T\n",
        "\n",
        "sentence_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "9jCfn-Q46Zcl",
        "outputId": "fda31942-ddcb-483d-efc8-6be46c1a4357"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    speaker                                           sentence objects\n",
              "000     000  OK. It is July 26, 4:20 PM and I'm here with p...      []\n",
              "104     104  sounds good  I didn’t even see that bag.  this...      []\n",
              "105     105  OK. Is my bag and stuff OK?  [throws {203} at ...      []\n",
              "106     106  OK  no.  all right. right off the bat they are...      []\n",
              "107     107  OK I don't think so  they're [201][202][203][2...      []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7b045c58-17e1-4c63-926e-c18d349ecc85\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>speaker</th>\n",
              "      <th>sentence</th>\n",
              "      <th>objects</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>000</th>\n",
              "      <td>000</td>\n",
              "      <td>OK. It is July 26, 4:20 PM and I'm here with p...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>104</td>\n",
              "      <td>sounds good  I didn’t even see that bag.  this...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>105</td>\n",
              "      <td>OK. Is my bag and stuff OK?  [throws {203} at ...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>106</td>\n",
              "      <td>OK  no.  all right. right off the bat they are...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>107</td>\n",
              "      <td>OK I don't think so  they're [201][202][203][2...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b045c58-17e1-4c63-926e-c18d349ecc85')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7b045c58-17e1-4c63-926e-c18d349ecc85 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7b045c58-17e1-4c63-926e-c18d349ecc85');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 3: tokens? Initial steps to data analysis\n",
        "\n",
        "The first step is to separate the sentence in its individual components. These components are called **tokens**. Note that tokens include individual words, but also commas and punctiation. Let's grab the third subject as an example\n",
        "\n",
        "1. Get the data from the column named `sentence` for subject with index `[2]`.\n"
      ],
      "metadata": {
        "id": "KsuA0g2qE4ae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example = sentence_data['sentence'][2]\n",
        "\n",
        "#single object with the entire sentence\n",
        "print(example)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtMMC95POava",
        "outputId": "bd2bdbc9-c438-437e-e17a-77d03420f3b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK. Is my bag and stuff OK?  [throws {203} at the wall and it falls off] OK so it's like sticks to like hard surfaces and like I said not always the best but when I was a kid and I would play with them and I was always--I would always like to do this [rolls ball on table so it sticks and unsticks, it makes popping sound] and like make popcorn noises. so it's also different colors red blue and green my hair is in it now. it's OK. but this is cool too. it's also a sphere but in like a subtle way because the middle is like a hard little circle and then this forms a circle but it's like all these little things. OK. Ooh. this [202] reminds me of like a pencil eraser almost, just in the way it looks and like the way it feels. I'm not super familiar with a bouncy ball like this, it's kind of like softer than a normal bouncy ball, like I feel like if this hit me it like wouldn't hurt as much. I don't know if that's true but I feel that way but yeah. it's cute. has the little barcode on it. so yeah, that's an observation. it has good bounce. it's it's a good like I feel like it's a good classic bouncy ball, although I do feel like it could be susceptible to like getting dirty because of how like soft it is and how light it is but yeah. Stay. and this [204] is a hacky sack. I have two hacky sacks at home. Yes, my--let's see it's like woven or like it's made of like thread, which is cool. and it has like little probably like beads inside of it just based on my knowledge of hacky sacks. um and yeah you're supposed to like [throws and drops 204] OK well if you're good at it, you're supposed to like be able to like bounce it off your body, but if you're like me you can't do that. but I like the colors on it the top kind of reminds me of like a strawberry almost but yeah. I feel like all of these things [201][202][203][204] serve different functions even though they're the same shape.  but the function is fun. Just different kinds of fun. is that enough?  OK  that is what I have to say about these. [201 lights up again]  OK OK I forgot it does that. OK OK gotcha  gotcha  I'm not on a timer now  OK this [205] is really interesting. still like some sort of like ball type thing. but I feel like the--like it doesn't bounce--you know it bounces in different directions because of all like the angles on it. I also kind of like rolling it around like I feel like you could use it as a muscle roller. oh OK have to observe it so it looks like stars that are like bunched together and they're all different colors and they're kind of like a thick rubbery plasticky material which I like and it's like hollow on the inside and it bounces in different directions. and I don't really know I never played with anything like this as like a kid very much I've like seen ‘em around but I think the fact that it like bounces in opposite directions made me not want to play with it because it meant I couldn't control it. But that says a lot about me. but no yeah different colors like it's fun you can squeeze it I don't know if it like moves or not I'm trying to like manipulate it but I don't think it does that so that is what I have to say about this guy. this [206] is like that thing's cousin it kind of like looks like the same thing except instead of like having pointy edges it's rounded but it's still kind of like a star or like a flower shape. I feel like I like this one better because it's like smoother and I feel like it's a pretty shape and it has like the same colors like orange yellow pink purple green blue, I think that's it but yeah. I like this. it's also hollow in the middle. never really like played with anything like this as a kid. these two [205][206] kind of like look similar in my mind like they have the same vibes. yeah it's kind of all I have to really say. let's see yeah OK this [208]  has like a dent in it, is it supposed to have a dent in it?  OK for the purpose--OK anyway, I shouldn’t ask that. OK, I like this one [208]. I had a lot of these as a kid because my mom was obsessed with everything being a learning opportunity and not just letting me have fun so I definitely like this, I think you can play with it but you can also like learn from it, I also think of fun game is to actually like be like where is like a certain country like that's fun for me. or continent or whatever. it's like squishy so it could also be like a stress ball type thing but also like you know catching [throws into the air and catches]. it's like very, very light. I'm actually not good at gua--I feel like this is heavier but this is like super light like very foamy, like very colorful, but like it has like the whole like globe on it which is cool, like separated by different colors which makes it easy and they're all like labeled too. So, yeah, my instinct is to squeeze it like this or to like toss it around in my hands like this. this thing, [207] this is weird. like this like looks like stuff I've played with before but it's like not, like it's very--it feels like hay or something it's like little rubber tendrils and it's green and yellow. and like it's fun to like fidget with but I don't think I would like play with this like if I were a kid I wouldn't wanna like play catch with it. Well, maybe I would like maybe it's actually kind of fun I don't know. but it's like an interesting texture. on my hands, kind of like almost like tussling through like really coarse hair or something like that so. oh there's actually hairs inside of it, someone's hair must have gotten it. but yeah. that's what I have to say about these balls.  more objects?  should I not touch it yet?  Oh my God  I love this thing [211] like I wanna take this home but I know I can't because it's for like science. but this is my favorite of all of them and it's kind of fun you can like stick your finger in it and just like move the liquid around and like the little shapes inside there are like 3 dolphins and it's supposed to be like the ocean. but this is definitely fun, definitely very different than like any of the other objects here. I don't even know what this [212] is, is it like a bead? Am I allowed to...know?  this looks like a— OK, this [212] looks like a bead. that's all I'm really getting from it. um this is not, you know it's cute, but it's not like giving. it's not giving. this [211] I love because it's like squishy and malleable and I think what attracts me to this [211] is like the risk. the fact that it could break like the fact that it could potentially get liquid all over me and like I can stick my finger through and it's like very fun, like this is the most fun to play with. I'll put down. this [210], is like another type like stress ball type thing but it's cool that shaped like a brain and it has like a nice kind of like texture has like a nice shape where you can just sit it somewhere, and it has this like branding on it so this is obviously used for some sort of capitalistic gain. and then this [209] is cute as well, like it's like a little body so it's shaped very differently than like the other things. you're not, you know, you could squeeze it, but I feel like I'm not meant to squeeze it. It’s green and it has like alien eyes and you can like kind of bend its legs well maybe you can bend them a lot. you can kind of bend them a lot actually, unless I'm just like really strong they're not supposed to do that. but it's kind of like an alien gumby so I like that, like how you can bend it. they're all different colors so this [212] is red this [211] is blue this [210] is purple this [209] is green. um but yeah I really like this one [211] in case it's not obvious. so yeah is there anything else I should say? OK goodbye, objects. whoa. and I can open them or no?  I can't open them.  Why? Did you do that? I like these [{213}-216]. this [{213}] feels like it has beans in it. this [{215}] this--feels like it maybe has like dried peas in it or something, but I don't know if that's really possible, I don't know how peas dry. this [216] OK so this definitely feels like sand, like a fine sand, not like super fine but like definitely like a fine sand. and then this [{214}] I would almost also say is like a sand but maybe like a little more coarse. and they're all [{213}-216] in these different bags which like this [{213}] is like they're [{213}-216] like very silky. I guess this one [{215}]--like this one [{213}] it's kind of easier to feel what's in it than this one [{215}] because this one [{215}] has like a lot of texture on it and this one [{213}] like is sort of silkier and smoother so I can kind of like feel around that way um like kind of same yeah honestly like kind of same with this one [{214}, 216] like honestly it's also different because like this [216] has more what I believe to be sand in it than this one [{214}] does. Wait, maybe that's the whole point. Maybe, maybe there are two sets [holding {213} with {215} and {214} with 216] of the same thing and one just has less in it. Why am I trying to—like--you know. but no anyway it's possible. Maybe these [holding {213}] are like little rocks or something. I don't know. but yeah they're fun to play with. I prefer kind of playing with this one [{213}] than I do with this one [216] because this one [{213}] I can like move them around more and this one [216] I'm just kind of like squishing in the sand. yeah I definitely like this one [{213}] but it's—yeah, there's something in there, something going on. so yeah. they're [{213}-216] pretty colors too, like the bags themselves have these like nice little designs they're like coin purses which I like but they're like filled with different things. and I feel like--I feel like if I knew how to juggle I would juggle these right now, like that's kind of the vibe I'm getting but I don't know how to juggle so I won't try. unless it would make your research more interesting.  but yeah, that is what I feel about these [213][214][215][216] so  Ok. Felt. [217] this is what I would like make Halloween costumes out of as a child because it's very like user friendly and you can like glue it. but it's like not like the most comfortable material. I feel like a lot of people don't really wear like felt, like I wouldn't really wear like a felt thing unless I were like a child who needed to. but it's red and it's like felt and it's like relatively soft so there is that. then there is this [218] which kind of feels like a bed sheet material to me. Um like kind of comfortable but like not the most comfortable. maybe also like kind of like a shirt--if I knew more about like different types of fabric I could probably try to guess what it was. Maybe like cotton, maybe like something, I don’t know. it's also like more flexible like you can scrunch it up better than—[scrunches up {217} and 218] well I just made it [{217}] wrinkly but like you can kind of scrunch it [218] up really small and that one [{217}]  you kind of can't. this [218] is like a darker maroon color. This-- [219] ooh, this is what I would actually want to have my sheets be made of because this feels like somehow like softer and like more comfortable than this one [218] does and has like a little designs on it not on the other side but yeah it's like soft it's like again like very flexible but it just like feels softer than this one so like these [218][219] are similar but like this one [219] is better feeling like to the touch and then this [220] is like lace which like cute but yeah it's got like some mesh going on and then some like like embroidery or like whatever happening. so it's white and it's like kind of stretchy. actually quite stretchy, at least compared to like this [219] is not very stretchy but this [220] is stretchy, probably because of like the maybe the mesh material or like what it's made of. yeah they're all [{217}-220] fabrics. Fabricky. this [{217}] one again like this one [{217}] you couldn’t--like you could bunch it up, but it’s just is a lot thicker. so so there’s that, that is that.  oh uh ah OK so this [224] is some sort of like canvas like burlapy material. my grandmother was like really poor and they actually made dresses out of like flour sacks or whatever which I think was like a really common thing for people to do. I mean, you know, the Dust Bowl.  That. And then, so like, this [224] is like not super stretchy um. I don't know. I feel like my first instinct with this is not like, clothing. it's like something else like maybe like a bag or like-- like when you're like casting like a fossil you like use burlap and then it like adheres to the the plaster that you're using.  cause it's like because this is flexible but still kind of like strong and like doesn't break super easily just because of like its weaving I guess so it's like very strong but I wouldn't say it's like the most comfortable like I wouldn't want to wear it, you know? but that's not always the function of like fabrics. this [223] is like kind of like faux fur vibe I'm feeling. um I enjoy it. this would be a good rug I actually have a rug that was very--had a rug that was very similar to this, and it kind of feels like a dog or like if someone has like super soft hair and I think it's probably made out of like that like plasticky material. like I don't sense that it's like real hair. it has this like backing to it which—i don’t know, which kind of like shows that it's not real maybe because it would be like leathery. What else? it's black it's dark, you can kind of like manipulate it and like move it around like could brush it all in one direction or all in the other direction or in like different directions and kind of play with it which is like what I liked to do when I had a rug like this, I would just like sit there like this. but yeah it's very soft very comfortable, again, probably wouldn't like wear it just because like it could also like get little bits stuck in it, yeah definitely has that vibe, like there's like this little piece of dust here but yeah this is this is pleasant. this [222] this is like really soft like I would—ooh--I would wear like some sort of like jacket with this as the lining in like winter. Ooh and it's like stretchy too. so yeah this is very fluffy kind of like the like Sherpa, Sherpa feeling. it's very nice, it's also like very soft on the other side and it's like stretchy and comfy and like I would use it as like a blanket in the winter or like some sort of like, like I said, like a lining to a jacket. it's like nice and white and it kind of reminds me of like sheep’s wool even though I don't think that's what it is, but it like reminds me of it. Or like, maybe it is, I don’t know, I’m not very good. but it's like--I like this, it's like one of my favorites thus far. and then this [221] is velvet, this is like reminds me of like a Halloween costume like someone who's going to be a vampire would maybe use this to like make a cape for themself. and it's also like kind of stretchy and elasticky, it's like crushed velvet so has this kind of like textured look, um which like, it is textured--but like the coloring is like kind of like fluid and it's not like one color. and it has like darker spots and it has lighter spots and it kind of like hits the light in a very interesting way, I feel like. like the color can kind of like change depending on how you scrunch it and things like that, so it like looks kind of dark here but then you like spread it out and it's light, so I don't know the science behind that, but like the light is hitting it at different angles which does a lot more to it than like say this thing [222] which just kind of like looks the same. this [221] almost looks like a like a liquid almost to me when I'm like moving it around. it's also like very soft and like nice to touch but because it's like crushed velvet like, like it's soft to touch but you can't like run your hand over it, like it kind of gets like some backlash, whereas like this [223] it's like that or like that [222] so. so yeah that is what I have to say about these items.  like an observation? not really. I want to touch this [211] more though. I don't have anything to say about it but, but yeah. I enjoy it. let me think. trying to think of more content for you. Yeah. I don't know, I mean like the objects change from like being like balls, like being things that you play with, to like just like being like more like tactile maybe things, so that was kind of cool. to play with these toys. but yeah, hopefully I described them enough for you. so that is what I have to say. thank you, thank thank you science.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "2. Use the package `nltk` to convert the sentence to tokens using the `word_tokenize()` method.\n"
      ],
      "metadata": {
        "id": "vdpgYI6wOOHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_tokenized = nltk.word_tokenize(example)\n",
        "\n",
        "# Tokenized version is an n x 1 array with as many objects as there are tokens\n",
        "print(example_tokenized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1807ALe04IK",
        "outputId": "70d6b525-0634-48f7-c9ab-f8ee6fbe54e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['OK.', 'Is', 'my', 'bag', 'and', 'stuff', 'OK', '?', '[', 'throws', '{', '203', '}', 'at', 'the', 'wall', 'and', 'it', 'falls', 'off', ']', 'OK', 'so', 'it', \"'s\", 'like', 'sticks', 'to', 'like', 'hard', 'surfaces', 'and', 'like', 'I', 'said', 'not', 'always', 'the', 'best', 'but', 'when', 'I', 'was', 'a', 'kid', 'and', 'I', 'would', 'play', 'with', 'them', 'and', 'I', 'was', 'always', '--', 'I', 'would', 'always', 'like', 'to', 'do', 'this', '[', 'rolls', 'ball', 'on', 'table', 'so', 'it', 'sticks', 'and', 'unsticks', ',', 'it', 'makes', 'popping', 'sound', ']', 'and', 'like', 'make', 'popcorn', 'noises', '.', 'so', 'it', \"'s\", 'also', 'different', 'colors', 'red', 'blue', 'and', 'green', 'my', 'hair', 'is', 'in', 'it', 'now', '.', 'it', \"'s\", 'OK.', 'but', 'this', 'is', 'cool', 'too', '.', 'it', \"'s\", 'also', 'a', 'sphere', 'but', 'in', 'like', 'a', 'subtle', 'way', 'because', 'the', 'middle', 'is', 'like', 'a', 'hard', 'little', 'circle', 'and', 'then', 'this', 'forms', 'a', 'circle', 'but', 'it', \"'s\", 'like', 'all', 'these', 'little', 'things', '.', 'OK.', 'Ooh', '.', 'this', '[', '202', ']', 'reminds', 'me', 'of', 'like', 'a', 'pencil', 'eraser', 'almost', ',', 'just', 'in', 'the', 'way', 'it', 'looks', 'and', 'like', 'the', 'way', 'it', 'feels', '.', 'I', \"'m\", 'not', 'super', 'familiar', 'with', 'a', 'bouncy', 'ball', 'like', 'this', ',', 'it', \"'s\", 'kind', 'of', 'like', 'softer', 'than', 'a', 'normal', 'bouncy', 'ball', ',', 'like', 'I', 'feel', 'like', 'if', 'this', 'hit', 'me', 'it', 'like', 'would', \"n't\", 'hurt', 'as', 'much', '.', 'I', 'do', \"n't\", 'know', 'if', 'that', \"'s\", 'true', 'but', 'I', 'feel', 'that', 'way', 'but', 'yeah', '.', 'it', \"'s\", 'cute', '.', 'has', 'the', 'little', 'barcode', 'on', 'it', '.', 'so', 'yeah', ',', 'that', \"'s\", 'an', 'observation', '.', 'it', 'has', 'good', 'bounce', '.', 'it', \"'s\", 'it', \"'s\", 'a', 'good', 'like', 'I', 'feel', 'like', 'it', \"'s\", 'a', 'good', 'classic', 'bouncy', 'ball', ',', 'although', 'I', 'do', 'feel', 'like', 'it', 'could', 'be', 'susceptible', 'to', 'like', 'getting', 'dirty', 'because', 'of', 'how', 'like', 'soft', 'it', 'is', 'and', 'how', 'light', 'it', 'is', 'but', 'yeah', '.', 'Stay', '.', 'and', 'this', '[', '204', ']', 'is', 'a', 'hacky', 'sack', '.', 'I', 'have', 'two', 'hacky', 'sacks', 'at', 'home', '.', 'Yes', ',', 'my', '--', 'let', \"'s\", 'see', 'it', \"'s\", 'like', 'woven', 'or', 'like', 'it', \"'s\", 'made', 'of', 'like', 'thread', ',', 'which', 'is', 'cool', '.', 'and', 'it', 'has', 'like', 'little', 'probably', 'like', 'beads', 'inside', 'of', 'it', 'just', 'based', 'on', 'my', 'knowledge', 'of', 'hacky', 'sacks', '.', 'um', 'and', 'yeah', 'you', \"'re\", 'supposed', 'to', 'like', '[', 'throws', 'and', 'drops', '204', ']', 'OK', 'well', 'if', 'you', \"'re\", 'good', 'at', 'it', ',', 'you', \"'re\", 'supposed', 'to', 'like', 'be', 'able', 'to', 'like', 'bounce', 'it', 'off', 'your', 'body', ',', 'but', 'if', 'you', \"'re\", 'like', 'me', 'you', 'ca', \"n't\", 'do', 'that', '.', 'but', 'I', 'like', 'the', 'colors', 'on', 'it', 'the', 'top', 'kind', 'of', 'reminds', 'me', 'of', 'like', 'a', 'strawberry', 'almost', 'but', 'yeah', '.', 'I', 'feel', 'like', 'all', 'of', 'these', 'things', '[', '201', ']', '[', '202', ']', '[', '203', ']', '[', '204', ']', 'serve', 'different', 'functions', 'even', 'though', 'they', \"'re\", 'the', 'same', 'shape', '.', 'but', 'the', 'function', 'is', 'fun', '.', 'Just', 'different', 'kinds', 'of', 'fun', '.', 'is', 'that', 'enough', '?', 'OK', 'that', 'is', 'what', 'I', 'have', 'to', 'say', 'about', 'these', '.', '[', '201', 'lights', 'up', 'again', ']', 'OK', 'OK', 'I', 'forgot', 'it', 'does', 'that', '.', 'OK', 'OK', 'gotcha', 'gotcha', 'I', \"'m\", 'not', 'on', 'a', 'timer', 'now', 'OK', 'this', '[', '205', ']', 'is', 'really', 'interesting', '.', 'still', 'like', 'some', 'sort', 'of', 'like', 'ball', 'type', 'thing', '.', 'but', 'I', 'feel', 'like', 'the', '--', 'like', 'it', 'does', \"n't\", 'bounce', '--', 'you', 'know', 'it', 'bounces', 'in', 'different', 'directions', 'because', 'of', 'all', 'like', 'the', 'angles', 'on', 'it', '.', 'I', 'also', 'kind', 'of', 'like', 'rolling', 'it', 'around', 'like', 'I', 'feel', 'like', 'you', 'could', 'use', 'it', 'as', 'a', 'muscle', 'roller', '.', 'oh', 'OK', 'have', 'to', 'observe', 'it', 'so', 'it', 'looks', 'like', 'stars', 'that', 'are', 'like', 'bunched', 'together', 'and', 'they', \"'re\", 'all', 'different', 'colors', 'and', 'they', \"'re\", 'kind', 'of', 'like', 'a', 'thick', 'rubbery', 'plasticky', 'material', 'which', 'I', 'like', 'and', 'it', \"'s\", 'like', 'hollow', 'on', 'the', 'inside', 'and', 'it', 'bounces', 'in', 'different', 'directions', '.', 'and', 'I', 'do', \"n't\", 'really', 'know', 'I', 'never', 'played', 'with', 'anything', 'like', 'this', 'as', 'like', 'a', 'kid', 'very', 'much', 'I', \"'ve\", 'like', 'seen', '‘', 'em', 'around', 'but', 'I', 'think', 'the', 'fact', 'that', 'it', 'like', 'bounces', 'in', 'opposite', 'directions', 'made', 'me', 'not', 'want', 'to', 'play', 'with', 'it', 'because', 'it', 'meant', 'I', 'could', \"n't\", 'control', 'it', '.', 'But', 'that', 'says', 'a', 'lot', 'about', 'me', '.', 'but', 'no', 'yeah', 'different', 'colors', 'like', 'it', \"'s\", 'fun', 'you', 'can', 'squeeze', 'it', 'I', 'do', \"n't\", 'know', 'if', 'it', 'like', 'moves', 'or', 'not', 'I', \"'m\", 'trying', 'to', 'like', 'manipulate', 'it', 'but', 'I', 'do', \"n't\", 'think', 'it', 'does', 'that', 'so', 'that', 'is', 'what', 'I', 'have', 'to', 'say', 'about', 'this', 'guy', '.', 'this', '[', '206', ']', 'is', 'like', 'that', 'thing', \"'s\", 'cousin', 'it', 'kind', 'of', 'like', 'looks', 'like', 'the', 'same', 'thing', 'except', 'instead', 'of', 'like', 'having', 'pointy', 'edges', 'it', \"'s\", 'rounded', 'but', 'it', \"'s\", 'still', 'kind', 'of', 'like', 'a', 'star', 'or', 'like', 'a', 'flower', 'shape', '.', 'I', 'feel', 'like', 'I', 'like', 'this', 'one', 'better', 'because', 'it', \"'s\", 'like', 'smoother', 'and', 'I', 'feel', 'like', 'it', \"'s\", 'a', 'pretty', 'shape', 'and', 'it', 'has', 'like', 'the', 'same', 'colors', 'like', 'orange', 'yellow', 'pink', 'purple', 'green', 'blue', ',', 'I', 'think', 'that', \"'s\", 'it', 'but', 'yeah', '.', 'I', 'like', 'this', '.', 'it', \"'s\", 'also', 'hollow', 'in', 'the', 'middle', '.', 'never', 'really', 'like', 'played', 'with', 'anything', 'like', 'this', 'as', 'a', 'kid', '.', 'these', 'two', '[', '205', ']', '[', '206', ']', 'kind', 'of', 'like', 'look', 'similar', 'in', 'my', 'mind', 'like', 'they', 'have', 'the', 'same', 'vibes', '.', 'yeah', 'it', \"'s\", 'kind', 'of', 'all', 'I', 'have', 'to', 'really', 'say', '.', 'let', \"'s\", 'see', 'yeah', 'OK', 'this', '[', '208', ']', 'has', 'like', 'a', 'dent', 'in', 'it', ',', 'is', 'it', 'supposed', 'to', 'have', 'a', 'dent', 'in', 'it', '?', 'OK', 'for', 'the', 'purpose', '--', 'OK', 'anyway', ',', 'I', 'shouldn', '’', 't', 'ask', 'that', '.', 'OK', ',', 'I', 'like', 'this', 'one', '[', '208', ']', '.', 'I', 'had', 'a', 'lot', 'of', 'these', 'as', 'a', 'kid', 'because', 'my', 'mom', 'was', 'obsessed', 'with', 'everything', 'being', 'a', 'learning', 'opportunity', 'and', 'not', 'just', 'letting', 'me', 'have', 'fun', 'so', 'I', 'definitely', 'like', 'this', ',', 'I', 'think', 'you', 'can', 'play', 'with', 'it', 'but', 'you', 'can', 'also', 'like', 'learn', 'from', 'it', ',', 'I', 'also', 'think', 'of', 'fun', 'game', 'is', 'to', 'actually', 'like', 'be', 'like', 'where', 'is', 'like', 'a', 'certain', 'country', 'like', 'that', \"'s\", 'fun', 'for', 'me', '.', 'or', 'continent', 'or', 'whatever', '.', 'it', \"'s\", 'like', 'squishy', 'so', 'it', 'could', 'also', 'be', 'like', 'a', 'stress', 'ball', 'type', 'thing', 'but', 'also', 'like', 'you', 'know', 'catching', '[', 'throws', 'into', 'the', 'air', 'and', 'catches', ']', '.', 'it', \"'s\", 'like', 'very', ',', 'very', 'light', '.', 'I', \"'m\", 'actually', 'not', 'good', 'at', 'gua', '--', 'I', 'feel', 'like', 'this', 'is', 'heavier', 'but', 'this', 'is', 'like', 'super', 'light', 'like', 'very', 'foamy', ',', 'like', 'very', 'colorful', ',', 'but', 'like', 'it', 'has', 'like', 'the', 'whole', 'like', 'globe', 'on', 'it', 'which', 'is', 'cool', ',', 'like', 'separated', 'by', 'different', 'colors', 'which', 'makes', 'it', 'easy', 'and', 'they', \"'re\", 'all', 'like', 'labeled', 'too', '.', 'So', ',', 'yeah', ',', 'my', 'instinct', 'is', 'to', 'squeeze', 'it', 'like', 'this', 'or', 'to', 'like', 'toss', 'it', 'around', 'in', 'my', 'hands', 'like', 'this', '.', 'this', 'thing', ',', '[', '207', ']', 'this', 'is', 'weird', '.', 'like', 'this', 'like', 'looks', 'like', 'stuff', 'I', \"'ve\", 'played', 'with', 'before', 'but', 'it', \"'s\", 'like', 'not', ',', 'like', 'it', \"'s\", 'very', '--', 'it', 'feels', 'like', 'hay', 'or', 'something', 'it', \"'s\", 'like', 'little', 'rubber', 'tendrils', 'and', 'it', \"'s\", 'green', 'and', 'yellow', '.', 'and', 'like', 'it', \"'s\", 'fun', 'to', 'like', 'fidget', 'with', 'but', 'I', 'do', \"n't\", 'think', 'I', 'would', 'like', 'play', 'with', 'this', 'like', 'if', 'I', 'were', 'a', 'kid', 'I', 'would', \"n't\", 'wan', 'na', 'like', 'play', 'catch', 'with', 'it', '.', 'Well', ',', 'maybe', 'I', 'would', 'like', 'maybe', 'it', \"'s\", 'actually', 'kind', 'of', 'fun', 'I', 'do', \"n't\", 'know', '.', 'but', 'it', \"'s\", 'like', 'an', 'interesting', 'texture', '.', 'on', 'my', 'hands', ',', 'kind', 'of', 'like', 'almost', 'like', 'tussling', 'through', 'like', 'really', 'coarse', 'hair', 'or', 'something', 'like', 'that', 'so', '.', 'oh', 'there', \"'s\", 'actually', 'hairs', 'inside', 'of', 'it', ',', 'someone', \"'s\", 'hair', 'must', 'have', 'gotten', 'it', '.', 'but', 'yeah', '.', 'that', \"'s\", 'what', 'I', 'have', 'to', 'say', 'about', 'these', 'balls', '.', 'more', 'objects', '?', 'should', 'I', 'not', 'touch', 'it', 'yet', '?', 'Oh', 'my', 'God', 'I', 'love', 'this', 'thing', '[', '211', ']', 'like', 'I', 'wan', 'na', 'take', 'this', 'home', 'but', 'I', 'know', 'I', 'ca', \"n't\", 'because', 'it', \"'s\", 'for', 'like', 'science', '.', 'but', 'this', 'is', 'my', 'favorite', 'of', 'all', 'of', 'them', 'and', 'it', \"'s\", 'kind', 'of', 'fun', 'you', 'can', 'like', 'stick', 'your', 'finger', 'in', 'it', 'and', 'just', 'like', 'move', 'the', 'liquid', 'around', 'and', 'like', 'the', 'little', 'shapes', 'inside', 'there', 'are', 'like', '3', 'dolphins', 'and', 'it', \"'s\", 'supposed', 'to', 'be', 'like', 'the', 'ocean', '.', 'but', 'this', 'is', 'definitely', 'fun', ',', 'definitely', 'very', 'different', 'than', 'like', 'any', 'of', 'the', 'other', 'objects', 'here', '.', 'I', 'do', \"n't\", 'even', 'know', 'what', 'this', '[', '212', ']', 'is', ',', 'is', 'it', 'like', 'a', 'bead', '?', 'Am', 'I', 'allowed', 'to', '...', 'know', '?', 'this', 'looks', 'like', 'a—', 'OK', ',', 'this', '[', '212', ']', 'looks', 'like', 'a', 'bead', '.', 'that', \"'s\", 'all', 'I', \"'m\", 'really', 'getting', 'from', 'it', '.', 'um', 'this', 'is', 'not', ',', 'you', 'know', 'it', \"'s\", 'cute', ',', 'but', 'it', \"'s\", 'not', 'like', 'giving', '.', 'it', \"'s\", 'not', 'giving', '.', 'this', '[', '211', ']', 'I', 'love', 'because', 'it', \"'s\", 'like', 'squishy', 'and', 'malleable', 'and', 'I', 'think', 'what', 'attracts', 'me', 'to', 'this', '[', '211', ']', 'is', 'like', 'the', 'risk', '.', 'the', 'fact', 'that', 'it', 'could', 'break', 'like', 'the', 'fact', 'that', 'it', 'could', 'potentially', 'get', 'liquid', 'all', 'over', 'me', 'and', 'like', 'I', 'can', 'stick', 'my', 'finger', 'through', 'and', 'it', \"'s\", 'like', 'very', 'fun', ',', 'like', 'this', 'is', 'the', 'most', 'fun', 'to', 'play', 'with', '.', 'I', \"'ll\", 'put', 'down', '.', 'this', '[', '210', ']', ',', 'is', 'like', 'another', 'type', 'like', 'stress', 'ball', 'type', 'thing', 'but', 'it', \"'s\", 'cool', 'that', 'shaped', 'like', 'a', 'brain', 'and', 'it', 'has', 'like', 'a', 'nice', 'kind', 'of', 'like', 'texture', 'has', 'like', 'a', 'nice', 'shape', 'where', 'you', 'can', 'just', 'sit', 'it', 'somewhere', ',', 'and', 'it', 'has', 'this', 'like', 'branding', 'on', 'it', 'so', 'this', 'is', 'obviously', 'used', 'for', 'some', 'sort', 'of', 'capitalistic', 'gain', '.', 'and', 'then', 'this', '[', '209', ']', 'is', 'cute', 'as', 'well', ',', 'like', 'it', \"'s\", 'like', 'a', 'little', 'body', 'so', 'it', \"'s\", 'shaped', 'very', 'differently', 'than', 'like', 'the', 'other', 'things', '.', 'you', \"'re\", 'not', ',', 'you', 'know', ',', 'you', 'could', 'squeeze', 'it', ',', 'but', 'I', 'feel', 'like', 'I', \"'m\", 'not', 'meant', 'to', 'squeeze', 'it', '.', 'It', '’', 's', 'green', 'and', 'it', 'has', 'like', 'alien', 'eyes', 'and', 'you', 'can', 'like', 'kind', 'of', 'bend', 'its', 'legs', 'well', 'maybe', 'you', 'can', 'bend', 'them', 'a', 'lot', '.', 'you', 'can', 'kind', 'of', 'bend', 'them', 'a', 'lot', 'actually', ',', 'unless', 'I', \"'m\", 'just', 'like', 'really', 'strong', 'they', \"'re\", 'not', 'supposed', 'to', 'do', 'that', '.', 'but', 'it', \"'s\", 'kind', 'of', 'like', 'an', 'alien', 'gumby', 'so', 'I', 'like', 'that', ',', 'like', 'how', 'you', 'can', 'bend', 'it', '.', 'they', \"'re\", 'all', 'different', 'colors', 'so', 'this', '[', '212', ']', 'is', 'red', 'this', '[', '211', ']', 'is', 'blue', 'this', '[', '210', ']', 'is', 'purple', 'this', '[', '209', ']', 'is', 'green', '.', 'um', 'but', 'yeah', 'I', 'really', 'like', 'this', 'one', '[', '211', ']', 'in', 'case', 'it', \"'s\", 'not', 'obvious', '.', 'so', 'yeah', 'is', 'there', 'anything', 'else', 'I', 'should', 'say', '?', 'OK', 'goodbye', ',', 'objects', '.', 'whoa', '.', 'and', 'I', 'can', 'open', 'them', 'or', 'no', '?', 'I', 'ca', \"n't\", 'open', 'them', '.', 'Why', '?', 'Did', 'you', 'do', 'that', '?', 'I', 'like', 'these', '[', '{', '213', '}', '-216', ']', '.', 'this', '[', '{', '213', '}', ']', 'feels', 'like', 'it', 'has', 'beans', 'in', 'it', '.', 'this', '[', '{', '215', '}', ']', 'this', '--', 'feels', 'like', 'it', 'maybe', 'has', 'like', 'dried', 'peas', 'in', 'it', 'or', 'something', ',', 'but', 'I', 'do', \"n't\", 'know', 'if', 'that', \"'s\", 'really', 'possible', ',', 'I', 'do', \"n't\", 'know', 'how', 'peas', 'dry', '.', 'this', '[', '216', ']', 'OK', 'so', 'this', 'definitely', 'feels', 'like', 'sand', ',', 'like', 'a', 'fine', 'sand', ',', 'not', 'like', 'super', 'fine', 'but', 'like', 'definitely', 'like', 'a', 'fine', 'sand', '.', 'and', 'then', 'this', '[', '{', '214', '}', ']', 'I', 'would', 'almost', 'also', 'say', 'is', 'like', 'a', 'sand', 'but', 'maybe', 'like', 'a', 'little', 'more', 'coarse', '.', 'and', 'they', \"'re\", 'all', '[', '{', '213', '}', '-216', ']', 'in', 'these', 'different', 'bags', 'which', 'like', 'this', '[', '{', '213', '}', ']', 'is', 'like', 'they', \"'re\", '[', '{', '213', '}', '-216', ']', 'like', 'very', 'silky', '.', 'I', 'guess', 'this', 'one', '[', '{', '215', '}', ']', '--', 'like', 'this', 'one', '[', '{', '213', '}', ']', 'it', \"'s\", 'kind', 'of', 'easier', 'to', 'feel', 'what', \"'s\", 'in', 'it', 'than', 'this', 'one', '[', '{', '215', '}', ']', 'because', 'this', 'one', '[', '{', '215', '}', ']', 'has', 'like', 'a', 'lot', 'of', 'texture', 'on', 'it', 'and', 'this', 'one', '[', '{', '213', '}', ']', 'like', 'is', 'sort', 'of', 'silkier', 'and', 'smoother', 'so', 'I', 'can', 'kind', 'of', 'like', 'feel', 'around', 'that', 'way', 'um', 'like', 'kind', 'of', 'same', 'yeah', 'honestly', 'like', 'kind', 'of', 'same', 'with', 'this', 'one', '[', '{', '214', '}', ',', '216', ']', 'like', 'honestly', 'it', \"'s\", 'also', 'different', 'because', 'like', 'this', '[', '216', ']', 'has', 'more', 'what', 'I', 'believe', 'to', 'be', 'sand', 'in', 'it', 'than', 'this', 'one', '[', '{', '214', '}', ']', 'does', '.', 'Wait', ',', 'maybe', 'that', \"'s\", 'the', 'whole', 'point', '.', 'Maybe', ',', 'maybe', 'there', 'are', 'two', 'sets', '[', 'holding', '{', '213', '}', 'with', '{', '215', '}', 'and', '{', '214', '}', 'with', '216', ']', 'of', 'the', 'same', 'thing', 'and', 'one', 'just', 'has', 'less', 'in', 'it', '.', 'Why', 'am', 'I', 'trying', 'to—like', '--', 'you', 'know', '.', 'but', 'no', 'anyway', 'it', \"'s\", 'possible', '.', 'Maybe', 'these', '[', 'holding', '{', '213', '}', ']', 'are', 'like', 'little', 'rocks', 'or', 'something', '.', 'I', 'do', \"n't\", 'know', '.', 'but', 'yeah', 'they', \"'re\", 'fun', 'to', 'play', 'with', '.', 'I', 'prefer', 'kind', 'of', 'playing', 'with', 'this', 'one', '[', '{', '213', '}', ']', 'than', 'I', 'do', 'with', 'this', 'one', '[', '216', ']', 'because', 'this', 'one', '[', '{', '213', '}', ']', 'I', 'can', 'like', 'move', 'them', 'around', 'more', 'and', 'this', 'one', '[', '216', ']', 'I', \"'m\", 'just', 'kind', 'of', 'like', 'squishing', 'in', 'the', 'sand', '.', 'yeah', 'I', 'definitely', 'like', 'this', 'one', '[', '{', '213', '}', ']', 'but', \"it's—yeah\", ',', 'there', \"'s\", 'something', 'in', 'there', ',', 'something', 'going', 'on', '.', 'so', 'yeah', '.', 'they', \"'re\", '[', '{', '213', '}', '-216', ']', 'pretty', 'colors', 'too', ',', 'like', 'the', 'bags', 'themselves', 'have', 'these', 'like', 'nice', 'little', 'designs', 'they', \"'re\", 'like', 'coin', 'purses', 'which', 'I', 'like', 'but', 'they', \"'re\", 'like', 'filled', 'with', 'different', 'things', '.', 'and', 'I', 'feel', 'like', '--', 'I', 'feel', 'like', 'if', 'I', 'knew', 'how', 'to', 'juggle', 'I', 'would', 'juggle', 'these', 'right', 'now', ',', 'like', 'that', \"'s\", 'kind', 'of', 'the', 'vibe', 'I', \"'m\", 'getting', 'but', 'I', 'do', \"n't\", 'know', 'how', 'to', 'juggle', 'so', 'I', 'wo', \"n't\", 'try', '.', 'unless', 'it', 'would', 'make', 'your', 'research', 'more', 'interesting', '.', 'but', 'yeah', ',', 'that', 'is', 'what', 'I', 'feel', 'about', 'these', '[', '213', ']', '[', '214', ']', '[', '215', ']', '[', '216', ']', 'so', 'Ok', '.', 'Felt', '.', '[', '217', ']', 'this', 'is', 'what', 'I', 'would', 'like', 'make', 'Halloween', 'costumes', 'out', 'of', 'as', 'a', 'child', 'because', 'it', \"'s\", 'very', 'like', 'user', 'friendly', 'and', 'you', 'can', 'like', 'glue', 'it', '.', 'but', 'it', \"'s\", 'like', 'not', 'like', 'the', 'most', 'comfortable', 'material', '.', 'I', 'feel', 'like', 'a', 'lot', 'of', 'people', 'do', \"n't\", 'really', 'wear', 'like', 'felt', ',', 'like', 'I', 'would', \"n't\", 'really', 'wear', 'like', 'a', 'felt', 'thing', 'unless', 'I', 'were', 'like', 'a', 'child', 'who', 'needed', 'to', '.', 'but', 'it', \"'s\", 'red', 'and', 'it', \"'s\", 'like', 'felt', 'and', 'it', \"'s\", 'like', 'relatively', 'soft', 'so', 'there', 'is', 'that', '.', 'then', 'there', 'is', 'this', '[', '218', ']', 'which', 'kind', 'of', 'feels', 'like', 'a', 'bed', 'sheet', 'material', 'to', 'me', '.', 'Um', 'like', 'kind', 'of', 'comfortable', 'but', 'like', 'not', 'the', 'most', 'comfortable', '.', 'maybe', 'also', 'like', 'kind', 'of', 'like', 'a', 'shirt', '--', 'if', 'I', 'knew', 'more', 'about', 'like', 'different', 'types', 'of', 'fabric', 'I', 'could', 'probably', 'try', 'to', 'guess', 'what', 'it', 'was', '.', 'Maybe', 'like', 'cotton', ',', 'maybe', 'like', 'something', ',', 'I', 'don', '’', 't', 'know', '.', 'it', \"'s\", 'also', 'like', 'more', 'flexible', 'like', 'you', 'can', 'scrunch', 'it', 'up', 'better', 'than—', '[', 'scrunches', 'up', '{', '217', '}', 'and', '218', ']', 'well', 'I', 'just', 'made', 'it', '[', '{', '217', '}', ']', 'wrinkly', 'but', 'like', 'you', 'can', 'kind', 'of', 'scrunch', 'it', '[', '218', ']', 'up', 'really', 'small', 'and', 'that', 'one', '[', '{', '217', '}', ']', 'you', 'kind', 'of', 'ca', \"n't\", '.', 'this', '[', '218', ']', 'is', 'like', 'a', 'darker', 'maroon', 'color', '.', 'This', '--', '[', '219', ']', 'ooh', ',', 'this', 'is', 'what', 'I', 'would', 'actually', 'want', 'to', 'have', 'my', 'sheets', 'be', 'made', 'of', 'because', 'this', 'feels', 'like', 'somehow', 'like', 'softer', 'and', 'like', 'more', 'comfortable', 'than', 'this', 'one', '[', '218', ']', 'does', 'and', 'has', 'like', 'a', 'little', 'designs', 'on', 'it', 'not', 'on', 'the', 'other', 'side', 'but', 'yeah', 'it', \"'s\", 'like', 'soft', 'it', \"'s\", 'like', 'again', 'like', 'very', 'flexible', 'but', 'it', 'just', 'like', 'feels', 'softer', 'than', 'this', 'one', 'so', 'like', 'these', '[', '218', ']', '[', '219', ']', 'are', 'similar', 'but', 'like', 'this', 'one', '[', '219', ']', 'is', 'better', 'feeling', 'like', 'to', 'the', 'touch', 'and', 'then', 'this', '[', '220', ']', 'is', 'like', 'lace', 'which', 'like', 'cute', 'but', 'yeah', 'it', \"'s\", 'got', 'like', 'some', 'mesh', 'going', 'on', 'and', 'then', 'some', 'like', 'like', 'embroidery', 'or', 'like', 'whatever', 'happening', '.', 'so', 'it', \"'s\", 'white', 'and', 'it', \"'s\", 'like', 'kind', 'of', 'stretchy', '.', 'actually', 'quite', 'stretchy', ',', 'at', 'least', 'compared', 'to', 'like', 'this', '[', '219', ']', 'is', 'not', 'very', 'stretchy', 'but', 'this', '[', '220', ']', 'is', 'stretchy', ',', 'probably', 'because', 'of', 'like', 'the', 'maybe', 'the', 'mesh', 'material', 'or', 'like', 'what', 'it', \"'s\", 'made', 'of', '.', 'yeah', 'they', \"'re\", 'all', '[', '{', '217', '}', '-220', ']', 'fabrics', '.', 'Fabricky', '.', 'this', '[', '{', '217', '}', ']', 'one', 'again', 'like', 'this', 'one', '[', '{', '217', '}', ']', 'you', 'couldn', '’', 't', '--', 'like', 'you', 'could', 'bunch', 'it', 'up', ',', 'but', 'it', '’', 's', 'just', 'is', 'a', 'lot', 'thicker', '.', 'so', 'so', 'there', '’', 's', 'that', ',', 'that', 'is', 'that', '.', 'oh', 'uh', 'ah', 'OK', 'so', 'this', '[', '224', ']', 'is', 'some', 'sort', 'of', 'like', 'canvas', 'like', 'burlapy', 'material', '.', 'my', 'grandmother', 'was', 'like', 'really', 'poor', 'and', 'they', 'actually', 'made', 'dresses', 'out', 'of', 'like', 'flour', 'sacks', 'or', 'whatever', 'which', 'I', 'think', 'was', 'like', 'a', 'really', 'common', 'thing', 'for', 'people', 'to', 'do', '.', 'I', 'mean', ',', 'you', 'know', ',', 'the', 'Dust', 'Bowl', '.', 'That', '.', 'And', 'then', ',', 'so', 'like', ',', 'this', '[', '224', ']', 'is', 'like', 'not', 'super', 'stretchy', 'um', '.', 'I', 'do', \"n't\", 'know', '.', 'I', 'feel', 'like', 'my', 'first', 'instinct', 'with', 'this', 'is', 'not', 'like', ',', 'clothing', '.', 'it', \"'s\", 'like', 'something', 'else', 'like', 'maybe', 'like', 'a', 'bag', 'or', 'like', '--', 'like', 'when', 'you', \"'re\", 'like', 'casting', 'like', 'a', 'fossil', 'you', 'like', 'use', 'burlap', 'and', 'then', 'it', 'like', 'adheres', 'to', 'the', 'the', 'plaster', 'that', 'you', \"'re\", 'using', '.', 'cause', 'it', \"'s\", 'like', 'because', 'this', 'is', 'flexible', 'but', 'still', 'kind', 'of', 'like', 'strong', 'and', 'like', 'does', \"n't\", 'break', 'super', 'easily', 'just', 'because', 'of', 'like', 'its', 'weaving', 'I', 'guess', 'so', 'it', \"'s\", 'like', 'very', 'strong', 'but', 'I', 'would', \"n't\", 'say', 'it', \"'s\", 'like', 'the', 'most', 'comfortable', 'like', 'I', 'would', \"n't\", 'want', 'to', 'wear', 'it', ',', 'you', 'know', '?', 'but', 'that', \"'s\", 'not', 'always', 'the', 'function', 'of', 'like', 'fabrics', '.', 'this', '[', '223', ']', 'is', 'like', 'kind', 'of', 'like', 'faux', 'fur', 'vibe', 'I', \"'m\", 'feeling', '.', 'um', 'I', 'enjoy', 'it', '.', 'this', 'would', 'be', 'a', 'good', 'rug', 'I', 'actually', 'have', 'a', 'rug', 'that', 'was', 'very', '--', 'had', 'a', 'rug', 'that', 'was', 'very', 'similar', 'to', 'this', ',', 'and', 'it', 'kind', 'of', 'feels', 'like', 'a', 'dog', 'or', 'like', 'if', 'someone', 'has', 'like', 'super', 'soft', 'hair', 'and', 'I', 'think', 'it', \"'s\", 'probably', 'made', 'out', 'of', 'like', 'that', 'like', 'plasticky', 'material', '.', 'like', 'I', 'do', \"n't\", 'sense', 'that', 'it', \"'s\", 'like', 'real', 'hair', '.', 'it', 'has', 'this', 'like', 'backing', 'to', 'it', 'which—i', 'don', '’', 't', 'know', ',', 'which', 'kind', 'of', 'like', 'shows', 'that', 'it', \"'s\", 'not', 'real', 'maybe', 'because', 'it', 'would', 'be', 'like', 'leathery', '.', 'What', 'else', '?', 'it', \"'s\", 'black', 'it', \"'s\", 'dark', ',', 'you', 'can', 'kind', 'of', 'like', 'manipulate', 'it', 'and', 'like', 'move', 'it', 'around', 'like', 'could', 'brush', 'it', 'all', 'in', 'one', 'direction', 'or', 'all', 'in', 'the', 'other', 'direction', 'or', 'in', 'like', 'different', 'directions', 'and', 'kind', 'of', 'play', 'with', 'it', 'which', 'is', 'like', 'what', 'I', 'liked', 'to', 'do', 'when', 'I', 'had', 'a', 'rug', 'like', 'this', ',', 'I', 'would', 'just', 'like', 'sit', 'there', 'like', 'this', '.', 'but', 'yeah', 'it', \"'s\", 'very', 'soft', 'very', 'comfortable', ',', 'again', ',', 'probably', 'would', \"n't\", 'like', 'wear', 'it', 'just', 'because', 'like', 'it', 'could', 'also', 'like', 'get', 'little', 'bits', 'stuck', 'in', 'it', ',', 'yeah', 'definitely', 'has', 'that', 'vibe', ',', 'like', 'there', \"'s\", 'like', 'this', 'little', 'piece', 'of', 'dust', 'here', 'but', 'yeah', 'this', 'is', 'this', 'is', 'pleasant', '.', 'this', '[', '222', ']', 'this', 'is', 'like', 'really', 'soft', 'like', 'I', 'would—ooh', '--', 'I', 'would', 'wear', 'like', 'some', 'sort', 'of', 'like', 'jacket', 'with', 'this', 'as', 'the', 'lining', 'in', 'like', 'winter', '.', 'Ooh', 'and', 'it', \"'s\", 'like', 'stretchy', 'too', '.', 'so', 'yeah', 'this', 'is', 'very', 'fluffy', 'kind', 'of', 'like', 'the', 'like', 'Sherpa', ',', 'Sherpa', 'feeling', '.', 'it', \"'s\", 'very', 'nice', ',', 'it', \"'s\", 'also', 'like', 'very', 'soft', 'on', 'the', 'other', 'side', 'and', 'it', \"'s\", 'like', 'stretchy', 'and', 'comfy', 'and', 'like', 'I', 'would', 'use', 'it', 'as', 'like', 'a', 'blanket', 'in', 'the', 'winter', 'or', 'like', 'some', 'sort', 'of', 'like', ',', 'like', 'I', 'said', ',', 'like', 'a', 'lining', 'to', 'a', 'jacket', '.', 'it', \"'s\", 'like', 'nice', 'and', 'white', 'and', 'it', 'kind', 'of', 'reminds', 'me', 'of', 'like', 'sheep', '’', 's', 'wool', 'even', 'though', 'I', 'do', \"n't\", 'think', 'that', \"'s\", 'what', 'it', 'is', ',', 'but', 'it', 'like', 'reminds', 'me', 'of', 'it', '.', 'Or', 'like', ',', 'maybe', 'it', 'is', ',', 'I', 'don', '’', 't', 'know', ',', 'I', '’', 'm', 'not', 'very', 'good', '.', 'but', 'it', \"'s\", 'like', '--', 'I', 'like', 'this', ',', 'it', \"'s\", 'like', 'one', 'of', 'my', 'favorites', 'thus', 'far', '.', 'and', 'then', 'this', '[', '221', ']', 'is', 'velvet', ',', 'this', 'is', 'like', 'reminds', 'me', 'of', 'like', 'a', 'Halloween', 'costume', 'like', 'someone', 'who', \"'s\", 'going', 'to', 'be', 'a', 'vampire', 'would', 'maybe', 'use', 'this', 'to', 'like', 'make', 'a', 'cape', 'for', 'themself', '.', 'and', 'it', \"'s\", 'also', 'like', 'kind', 'of', 'stretchy', 'and', 'elasticky', ',', 'it', \"'s\", 'like', 'crushed', 'velvet', 'so', 'has', 'this', 'kind', 'of', 'like', 'textured', 'look', ',', 'um', 'which', 'like', ',', 'it', 'is', 'textured', '--', 'but', 'like', 'the', 'coloring', 'is', 'like', 'kind', 'of', 'like', 'fluid', 'and', 'it', \"'s\", 'not', 'like', 'one', 'color', '.', 'and', 'it', 'has', 'like', 'darker', 'spots', 'and', 'it', 'has', 'lighter', 'spots', 'and', 'it', 'kind', 'of', 'like', 'hits', 'the', 'light', 'in', 'a', 'very', 'interesting', 'way', ',', 'I', 'feel', 'like', '.', 'like', 'the', 'color', 'can', 'kind', 'of', 'like', 'change', 'depending', 'on', 'how', 'you', 'scrunch', 'it', 'and', 'things', 'like', 'that', ',', 'so', 'it', 'like', 'looks', 'kind', 'of', 'dark', 'here', 'but', 'then', 'you', 'like', 'spread', 'it', 'out', 'and', 'it', \"'s\", 'light', ',', 'so', 'I', 'do', \"n't\", 'know', 'the', 'science', 'behind', 'that', ',', 'but', 'like', 'the', 'light', 'is', 'hitting', 'it', 'at', 'different', 'angles', 'which', 'does', 'a', 'lot', 'more', 'to', 'it', 'than', 'like', 'say', 'this', 'thing', '[', '222', ']', 'which', 'just', 'kind', 'of', 'like', 'looks', 'the', 'same', '.', 'this', '[', '221', ']', 'almost', 'looks', 'like', 'a', 'like', 'a', 'liquid', 'almost', 'to', 'me', 'when', 'I', \"'m\", 'like', 'moving', 'it', 'around', '.', 'it', \"'s\", 'also', 'like', 'very', 'soft', 'and', 'like', 'nice', 'to', 'touch', 'but', 'because', 'it', \"'s\", 'like', 'crushed', 'velvet', 'like', ',', 'like', 'it', \"'s\", 'soft', 'to', 'touch', 'but', 'you', 'ca', \"n't\", 'like', 'run', 'your', 'hand', 'over', 'it', ',', 'like', 'it', 'kind', 'of', 'gets', 'like', 'some', 'backlash', ',', 'whereas', 'like', 'this', '[', '223', ']', 'it', \"'s\", 'like', 'that', 'or', 'like', 'that', '[', '222', ']', 'so', '.', 'so', 'yeah', 'that', 'is', 'what', 'I', 'have', 'to', 'say', 'about', 'these', 'items', '.', 'like', 'an', 'observation', '?', 'not', 'really', '.', 'I', 'want', 'to', 'touch', 'this', '[', '211', ']', 'more', 'though', '.', 'I', 'do', \"n't\", 'have', 'anything', 'to', 'say', 'about', 'it', 'but', ',', 'but', 'yeah', '.', 'I', 'enjoy', 'it', '.', 'let', 'me', 'think', '.', 'trying', 'to', 'think', 'of', 'more', 'content', 'for', 'you', '.', 'Yeah', '.', 'I', 'do', \"n't\", 'know', ',', 'I', 'mean', 'like', 'the', 'objects', 'change', 'from', 'like', 'being', 'like', 'balls', ',', 'like', 'being', 'things', 'that', 'you', 'play', 'with', ',', 'to', 'like', 'just', 'like', 'being', 'like', 'more', 'like', 'tactile', 'maybe', 'things', ',', 'so', 'that', 'was', 'kind', 'of', 'cool', '.', 'to', 'play', 'with', 'these', 'toys', '.', 'but', 'yeah', ',', 'hopefully', 'I', 'described', 'them', 'enough', 'for', 'you', '.', 'so', 'that', 'is', 'what', 'I', 'have', 'to', 'say', '.', 'thank', 'you', ',', 'thank', 'thank', 'you', 'science', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. use the `pos_tag()` method which returns the pos (part-of-speech) tag.\n",
        "---\n",
        "ℹ️ Python starts counting with 0. So the first object is in position `[0]`, and the third object is in position `[2]`\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Utval5p1Ogm5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_postag = nltk.pos_tag(example)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "UMx-uto4OKzA",
        "outputId": "6b41a40a-401c-477e-c75c-3a1f1052302c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-9d5c8efb052e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexample_postag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tag/__init__.py\u001b[0m in \u001b[0;36mpos_tag\u001b[0;34m(tokens, tagset, lang)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \"\"\"\n\u001b[1;32m    165\u001b[0m     \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_tagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_pos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tag/__init__.py\u001b[0m in \u001b[0;36m_pos_tag\u001b[0;34m(tokens, tagset, tagger, lang)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;31m# Throws Error if tokens is of string type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tokens: expected a list of strings, got a string\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: tokens: expected a list of strings, got a string"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install --target=$nb_path docx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAeb7wtUO7Kt",
        "outputId": "5d43be8f-5b4b-488f-8b02-448485d78217"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting docx\n",
            "  Using cached docx-0.2.4-py3-none-any.whl\n",
            "Collecting lxml (from docx)\n",
            "  Downloading lxml-4.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow>=2.0 (from docx)\n",
            "  Downloading Pillow-9.5.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OJAU_yeptDvr",
        "outputId": "12725b25-ad8d-4117-8bf7-90d82a1169b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> l\n",
            "Packages:\n",
            "  [ ] abc................. Australian Broadcasting Commission 2006\n",
            "  [ ] alpino.............. Alpino Dutch Treebank\n",
            "  [ ] averaged_perceptron_tagger Averaged Perceptron Tagger\n",
            "  [ ] averaged_perceptron_tagger_ru Averaged Perceptron Tagger (Russian)\n",
            "  [ ] basque_grammars..... Grammars for Basque\n",
            "  [ ] bcp47............... BCP-47 Language Tags\n",
            "  [ ] biocreative_ppi..... BioCreAtIvE (Critical Assessment of Information\n",
            "                           Extraction Systems in Biology)\n",
            "  [ ] bllip_wsj_no_aux.... BLLIP Parser: WSJ Model\n",
            "  [ ] book_grammars....... Grammars from NLTK Book\n",
            "  [ ] brown............... Brown Corpus\n",
            "  [ ] brown_tei........... Brown Corpus (TEI XML Version)\n",
            "  [ ] cess_cat............ CESS-CAT Treebank\n",
            "  [ ] cess_esp............ CESS-ESP Treebank\n",
            "  [ ] chat80.............. Chat-80 Data Files\n",
            "  [ ] city_database....... City Database\n",
            "  [ ] cmudict............. The Carnegie Mellon Pronouncing Dictionary (0.6)\n",
            "  [ ] comparative_sentences Comparative Sentence Dataset\n",
            "  [ ] comtrans............ ComTrans Corpus Sample\n",
            "  [ ] conll2000........... CONLL 2000 Chunking Corpus\n",
            "Hit Enter to continue: \n",
            "  [ ] conll2002........... CONLL 2002 Named Entity Recognition Corpus\n",
            "  [ ] conll2007........... Dependency Treebanks from CoNLL 2007 (Catalan\n",
            "                           and Basque Subset)\n",
            "  [ ] crubadan............ Crubadan Corpus\n",
            "  [ ] dependency_treebank. Dependency Parsed Treebank\n",
            "  [ ] dolch............... Dolch Word List\n",
            "  [ ] europarl_raw........ Sample European Parliament Proceedings Parallel\n",
            "                           Corpus\n",
            "  [ ] extended_omw........ Extended Open Multilingual WordNet\n",
            "  [ ] floresta............ Portuguese Treebank\n",
            "  [ ] framenet_v15........ FrameNet 1.5\n",
            "  [ ] framenet_v17........ FrameNet 1.7\n",
            "  [ ] gazetteers.......... Gazeteer Lists\n",
            "  [ ] genesis............. Genesis Corpus\n",
            "  [ ] gutenberg........... Project Gutenberg Selections\n",
            "  [ ] ieer................ NIST IE-ER DATA SAMPLE\n",
            "  [ ] inaugural........... C-Span Inaugural Address Corpus\n",
            "  [ ] indian.............. Indian Language POS-Tagged Corpus\n",
            "  [ ] jeita............... JEITA Public Morphologically Tagged Corpus (in\n",
            "                           ChaSen format)\n",
            "  [ ] kimmo............... PC-KIMMO Data Files\n",
            "Hit Enter to continue: punkt\n",
            "  [ ] knbc................ KNB Corpus (Annotated blog corpus)\n",
            "  [ ] large_grammars...... Large context-free and feature-based grammars\n",
            "                           for parser comparison\n",
            "  [ ] lin_thesaurus....... Lin's Dependency Thesaurus\n",
            "  [ ] mac_morpho.......... MAC-MORPHO: Brazilian Portuguese news text with\n",
            "                           part-of-speech tags\n",
            "  [ ] machado............. Machado de Assis -- Obra Completa\n",
            "  [ ] masc_tagged......... MASC Tagged Corpus\n",
            "  [ ] maxent_ne_chunker... ACE Named Entity Chunker (Maximum entropy)\n",
            "  [ ] maxent_treebank_pos_tagger Treebank Part of Speech Tagger (Maximum entropy)\n",
            "  [ ] moses_sample........ Moses Sample Models\n",
            "  [ ] movie_reviews....... Sentiment Polarity Dataset Version 2.0\n",
            "  [ ] mte_teip5........... MULTEXT-East 1984 annotated corpus 4.0\n",
            "  [ ] mwa_ppdb............ The monolingual word aligner (Sultan et al.\n",
            "                           2015) subset of the Paraphrase Database.\n",
            "  [ ] names............... Names Corpus, Version 1.3 (1994-03-29)\n",
            "  [ ] nombank.1.0......... NomBank Corpus 1.0\n",
            "  [ ] nonbreaking_prefixes Non-Breaking Prefixes (Moses Decoder)\n",
            "  [ ] nps_chat............ NPS Chat\n",
            "  [ ] omw-1.4............. Open Multilingual Wordnet\n",
            "  [ ] omw................. Open Multilingual Wordnet\n",
            "Hit Enter to continue: \n",
            "  [ ] opinion_lexicon..... Opinion Lexicon\n",
            "  [ ] panlex_swadesh...... PanLex Swadesh Corpora\n",
            "  [ ] paradigms........... Paradigm Corpus\n",
            "  [ ] pe08................ Cross-Framework and Cross-Domain Parser\n",
            "                           Evaluation Shared Task\n",
            "  [ ] perluniprops........ perluniprops: Index of Unicode Version 7.0.0\n",
            "                           character properties in Perl\n",
            "  [ ] pil................. The Patient Information Leaflet (PIL) Corpus\n",
            "  [ ] pl196x.............. Polish language of the XX century sixties\n",
            "  [ ] porter_test......... Porter Stemmer Test Files\n",
            "  [ ] ppattach............ Prepositional Phrase Attachment Corpus\n",
            "  [ ] problem_reports..... Problem Report Corpus\n",
            "  [ ] product_reviews_1... Product Reviews (5 Products)\n",
            "  [ ] product_reviews_2... Product Reviews (9 Products)\n",
            "  [ ] propbank............ Proposition Bank Corpus 1.0\n",
            "  [ ] pros_cons........... Pros and Cons\n",
            "  [ ] ptb................. Penn Treebank\n",
            "  [ ] punkt............... Punkt Tokenizer Models\n",
            "  [ ] qc.................. Experimental Data for Question Classification\n",
            "  [ ] reuters............. The Reuters-21578 benchmark corpus, ApteMod\n",
            "                           version\n",
            "Hit Enter to continue: \n",
            "  [ ] rslp................ RSLP Stemmer (Removedor de Sufixos da Lingua\n",
            "                           Portuguesa)\n",
            "  [ ] rte................. PASCAL RTE Challenges 1, 2, and 3\n",
            "  [ ] sample_grammars..... Sample Grammars\n",
            "  [ ] semcor.............. SemCor 3.0\n",
            "  [ ] senseval............ SENSEVAL 2 Corpus: Sense Tagged Text\n",
            "  [ ] sentence_polarity... Sentence Polarity Dataset v1.0\n",
            "  [ ] sentiwordnet........ SentiWordNet\n",
            "  [ ] shakespeare......... Shakespeare XML Corpus Sample\n",
            "  [ ] sinica_treebank..... Sinica Treebank Corpus Sample\n",
            "  [ ] smultron............ SMULTRON Corpus Sample\n",
            "  [ ] snowball_data....... Snowball Data\n",
            "  [ ] spanish_grammars.... Grammars for Spanish\n",
            "  [ ] state_union......... C-Span State of the Union Address Corpus\n",
            "  [ ] stopwords........... Stopwords Corpus\n",
            "  [ ] subjectivity........ Subjectivity Dataset v1.0\n",
            "  [ ] swadesh............. Swadesh Wordlists\n",
            "  [ ] switchboard......... Switchboard Corpus Sample\n",
            "  [ ] tagsets............. Help on Tagsets\n",
            "  [ ] timit............... TIMIT Corpus Sample\n",
            "  [ ] toolbox............. Toolbox Sample Files\n",
            "Hit Enter to continue: \n",
            "  [ ] treebank............ Penn Treebank Sample\n",
            "  [ ] twitter_samples..... Twitter Samples\n",
            "  [ ] udhr2............... Universal Declaration of Human Rights Corpus\n",
            "                           (Unicode Version)\n",
            "  [ ] udhr................ Universal Declaration of Human Rights Corpus\n",
            "  [ ] unicode_samples..... Unicode Samples\n",
            "  [ ] universal_tagset.... Mappings to the Universal Part-of-Speech Tagset\n",
            "  [ ] universal_treebanks_v20 Universal Treebanks Version 2.0\n",
            "  [ ] vader_lexicon....... VADER Sentiment Lexicon\n",
            "  [ ] verbnet3............ VerbNet Lexicon, Version 3.3\n",
            "  [ ] verbnet............. VerbNet Lexicon, Version 2.1\n",
            "  [ ] webtext............. Web Text Corpus\n",
            "  [ ] wmt15_eval.......... Evaluation data from WMT15\n",
            "  [ ] word2vec_sample..... Word2Vec Sample\n",
            "  [ ] wordnet2021......... Open English Wordnet 2021\n",
            "  [ ] wordnet2022......... Open English Wordnet 2022\n",
            "  [ ] wordnet31........... Wordnet 3.1\n",
            "  [ ] wordnet............. WordNet\n",
            "  [ ] wordnet_ic.......... WordNet-InfoContent\n",
            "  [ ] words............... Word Lists\n",
            "  [ ] ycoe................ York-Toronto-Helsinki Parsed Corpus of Old\n",
            "                           English Prose\n",
            "Hit Enter to continue: \n",
            "\n",
            "Collections:\n",
            "  [ ] all-corpora......... All the corpora\n",
            "  [ ] all-nltk............ All packages available on nltk_data gh-pages\n",
            "                           branch\n",
            "  [ ] all................. All packages\n",
            "  [ ] book................ Everything used in the NLTK Book\n",
            "  [ ] popular............. Popular packages\n",
            "  [ ] tests............... Packages for running tests\n",
            "  [ ] third-party......... Third-party data packages\n",
            "\n",
            "([*] marks installed packages)\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> punkt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    Downloading package punkt to /root/nltk_data...\n",
            "      Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-6e230a00a763>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/downloader.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self, info_or_id, download_dir, quiet, force, prefix, halt_on_error, raise_on_error, print_error_to)\u001b[0m\n\u001b[1;32m    761\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdownload_dir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interactive_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/downloader.py\u001b[0m in \u001b[0;36m_interactive_download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1113\u001b[0m                 \u001b[0mDownloaderGUI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTclError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m                 \u001b[0mDownloaderShell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m             \u001b[0mDownloaderShell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/downloader.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1139\u001b[0m                 \u001b[0;34m\"q) Quit\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m             )\n\u001b[0;32m-> 1141\u001b[0;31m             \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Downloader> \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1142\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": []
    }
  ]
}
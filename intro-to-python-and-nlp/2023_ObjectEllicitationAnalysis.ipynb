{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNXr3/NYhWzzhB1dpi4fBtS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yurisugano/Object-Ellicitation-NLP/blob/main/2023_ObjectEllicitationAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preface:\n",
        "\n",
        "Start by copying this colab to your Drive in \"File\" > \"Save a copy in Drive\". This allows you to modify the code.\n",
        "\n",
        "Run code by pressing play in each cell. Results will be shown immediately after the code. Press play in the cell below to run it. The cell will download the Transcript data from GitHub. and print \"done\".\n"
      ],
      "metadata": {
        "id": "SlULsrj2BS9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!rm -rf ObjectEllicitationNLP\n",
        "!git clone https://github.com/yurisugano/ObjectEllicitationNLP.git\n",
        "\n",
        "print(\"done\")"
      ],
      "metadata": {
        "id": "ji6z8xFAVGzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Text cleaning"
      ],
      "metadata": {
        "id": "QAQcL5-C27Mh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 1.1 Loading the data\n",
        "\n",
        "Load the transcript data and organize its structure.\n",
        "\n",
        "1. Read the `Transcripts.docx` file into a `doc` object.\n",
        "2. Each paragraph in the `doc` object corresponds to one sentence stated by a subject\n",
        "3. Format so all subject and object notation is consistent:\n",
        "  - Enclose all three digit numbers that are not enclosed in curly braces\n",
        "  - Remove spaces and dashes\n",
        "4. Lastly, all sentences said by a subject are grouped together. Specifically, each dictionary object will be in the format of `{'speaker': \"SpeakerID\", 'sentence': <\"Everything subject has said\"> o, 'objects': <\"All object references\">}`.\n",
        "\n",
        "---\n",
        "ℹ️ In the code, packages used in the block are imported first. Then, functions that perform the manipulations are defined. Lastly, a for loop applies these functions to each paragraph in the transcript.\n",
        "\n",
        "It is a good habit to include a sentence describing what a function does as a comment in the first line of its definition.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "2PdrVlkHfR9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load necessary packages\n",
        "!pip install python-docx\n",
        "import re\n",
        "from docx import Document\n",
        "\n",
        "# Read the transcript from the cloud\n",
        "raw_data = Document('/content/ObjectEllicitationNLP/Transcripts.docx')\n",
        "\n",
        "\n",
        "# Define functions to handle formatting\n",
        "def add_curly_braces(paragraph_text):\n",
        "    \"\"\"Add curly braces to three-digit numbers not surrounded by square brackets or curly braces.\"\"\"\n",
        "    numbers = re.findall(r'(?<![\\[{])\\b(\\d{3})\\b(?![\\]}])', paragraph_text)\n",
        "    for number in numbers:\n",
        "        transformed_number = '{' + number + '}'\n",
        "        paragraph_text = re.sub(r'\\b' + number + r'\\b', transformed_number, paragraph_text)\n",
        "    return paragraph_text\n",
        "\n",
        "def handle_square_brackets(paragraph_text):\n",
        "    \"\"\"Handle numbers inside square brackets with optional spaces and dashes.\"\"\"\n",
        "    matches = re.findall(r'\\[([\\d\\s,-]+)\\]', paragraph_text)\n",
        "    for match in matches:\n",
        "        numbers = []\n",
        "        for num_range in re.split(r',\\s*|\\s+', match):\n",
        "            num_range = num_range.strip()\n",
        "            if '-' in num_range:\n",
        "                start, end = num_range.split('-')\n",
        "                numbers.extend(range(int(start), int(end) + 1))\n",
        "            else:\n",
        "                numbers.append(int(num_range))\n",
        "\n",
        "        transformed = '[' + ']['.join(map(str, numbers)) + ']'\n",
        "        paragraph_text = paragraph_text.replace('[' + match + ']', transformed)\n",
        "    return paragraph_text\n",
        "\n",
        "# Iterate over each paragraph\n",
        "for each_paragraph in raw_data.paragraphs:\n",
        "    each_paragraph.text = add_curly_braces(each_paragraph.text)\n",
        "    each_paragraph.text = handle_square_brackets(each_paragraph.text)\n",
        "\n"
      ],
      "metadata": {
        "id": "ocIAqJkg3bvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize what one paragraph looks like\n",
        "print(raw_data.paragraphs[4].text)"
      ],
      "metadata": {
        "id": "oFlFLAlNjuNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, each paragraph consists of a subject identifier e.g. `{104}` and a single sentence. We need to gather all the sentences for each subject."
      ],
      "metadata": {
        "id": "M4y_oQ1Ilh1Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Extracting Subjects and Sentences\n",
        "\n",
        "\n",
        "1. Loop through each paragraph again, now extracting\n",
        "  - `speaker` with all three digit numbers surrounded by `{ }`\n",
        "  - `sentence` for the entire string after `:`\n",
        "  - `objects` for all three digit numbers surrounded by `[ ]`\n",
        "\n",
        "2. Concatenate alll sentences by the same speaker in a single string.\n",
        "3. Lastly, create a dictionary named `data`, organized as follows:\n",
        "  `{subjectID: {subjectID: subjectID, statements: [\"Statement1\", \"Statement2\", ...], objects: [201, 202, ...]}`\n",
        "  - All objects are listed in the order they appear. Repeats are allowed so we can, for example, easily determine which objects are more popular"
      ],
      "metadata": {
        "id": "dU4wbQnS29gp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_info(paragraph_text):\n",
        "    \"\"\"Extract speaker, sentences, and objects from a paragraph text.\"\"\"\n",
        "    speaker_match = re.search(r'\\{(\\d{3})\\}', paragraph_text)\n",
        "    sentence_match = re.search(r': (.*)', paragraph_text)\n",
        "    objects_match = re.findall(r'\\[(\\d{3})\\]', paragraph_text)\n",
        "\n",
        "    if speaker_match and sentence_match:\n",
        "        speaker = speaker_match.group(1)\n",
        "        sentence = sentence_match.group(1)\n",
        "        objects = [int(object_id) for object_id in objects_match]\n",
        "        return speaker, sentence, objects\n",
        "    else:\n",
        "        return None, None, None\n",
        "\n",
        "\n",
        "def update_data(data, speaker, sentence, objects):\n",
        "    \"\"\"Update data dictionary with extracted speaker, sentence, and objects.\"\"\"\n",
        "    if speaker:\n",
        "        if speaker in data:\n",
        "            data[speaker]['statements'].append(sentence)\n",
        "            data[speaker]['objects'].extend(objects)\n",
        "        else:\n",
        "            data[speaker] = {'subject': speaker, 'statements': [statement], 'objects': objects}\n",
        "\n",
        "# Initialize an empty dictionary to store the data\n",
        "data = {}\n",
        "\n",
        "# Loop over each paragraph in the document\n",
        "for each_paragraph in raw_data.paragraphs:\n",
        "    speaker, statement, objects = extract_info(each_paragraph.text)\n",
        "    update_data(data, speaker, statement, objects)"
      ],
      "metadata": {
        "id": "9jCfn-Q46Zcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data is now organized in a dictionary."
      ],
      "metadata": {
        "id": "xpZOFULdA1rs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, each row in the dictionary has a speaker tag, all the sentences stated by that speaker, and the objects referenced within that paragraph. This is a quick way to check if a subject has mentioned all the objects. Let's look at an entire sentence using subject 106 as an example."
      ],
      "metadata": {
        "id": "CNIUkT3xmJWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(data['106']['statements'])\n",
        "print(data['106']['statements'][10])\n"
      ],
      "metadata": {
        "id": "v8-2HYO5mT9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Pre-processing #"
      ],
      "metadata": {
        "id": "KsuA0g2qE4ae"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 2.1: Word tokenization\n",
        "\n",
        "The first step is to separate the entire speech in its individual components. These components are called **tokens**. Tokens may include individual words, but also commas and punctiation. Let's grab the one random sentence as an example\n"
      ],
      "metadata": {
        "id": "m4PlEXbJfXYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick subject 104 sentence id 16 as an example\n",
        "sentence = data['104']['statements'][16]\n",
        "\n",
        "print(sentence)"
      ],
      "metadata": {
        "id": "AtMMC95POava"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. Use the package `nltk` to convert the sentence to tokens using the `word_tokenize()` method.\n",
        "\n",
        "Display the first 10 elements (`[:9]`)\n"
      ],
      "metadata": {
        "id": "vdpgYI6wOOHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the nltk library\n",
        "import nltk\n",
        "\n",
        "# Download the 'punkt' library, used for tokenization\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Tokenize the example sentnece\n",
        "sentence_tokens = nltk.word_tokenize(sentence)\n",
        "\n",
        "# Print the first 10 tokens\n",
        "print(sentence_tokens[:9])"
      ],
      "metadata": {
        "id": "E1807ALe04IK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Object references such as [220] are being treated as tokens. To create a purely text string, let's create a new key inside the dictionary called `statement_clean`, and remove all references to objects or speakers."
      ],
      "metadata": {
        "id": "N4kffEScJaZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through each subject : subject_data pair in the data dictionary\n",
        "for subject, subject_data in data.items():\n",
        "    statements = subject_data[\"statements\"]\n",
        "    cleaned_statements = []\n",
        "\n",
        "    # Loop through each sentence and remove references to objects\n",
        "    for sentence in statements:\n",
        "        cleaned_sentence = re.sub(r'\\{.*?\\} | \\[.*?\\]', \"\", sentence)\n",
        "        cleaned_statements.append(cleaned_sentence)\n",
        "\n",
        "    subject_data[\"clean_statements\"] = cleaned_statements\n",
        "\n",
        "clean_sentence = data['104']['clean_statements'][16]\n",
        "print(clean_sentence)"
      ],
      "metadata": {
        "id": "SjXzXmMzPe4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Good, now every sentence is plain text. Back to tokenization"
      ],
      "metadata": {
        "id": "1RRrec9EOGSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the example sentence, now clean\n",
        "sentence_tokens = nltk.word_tokenize(clean_sentence)\n",
        "\n",
        "print(sentence_tokens[:9])"
      ],
      "metadata": {
        "id": "drLtnTWrOQbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Create a new `key: value` pair inside our dictionary to group all tokens for each subject"
      ],
      "metadata": {
        "id": "lUsn4_yaOokA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through eac subject : subject_data pair\n",
        "for subject, subject_data in data.items():\n",
        "    # Initialize an empty all_tokens list\n",
        "    all_tokens = []\n",
        "\n",
        "    # Store all the tokens in the all_tokens list with the .extend method\n",
        "    for sentence in subject_data[\"statements\"]:\n",
        "        all_tokens.extend(nltk.word_tokenize(sentence))\n",
        "    # Add the entry to the dictionary\n",
        "    subject_data[\"all_tokens\"] = all_tokens\n",
        "\n",
        "print(data['104']['all_tokens'][:9])\n"
      ],
      "metadata": {
        "id": "gP0oDUwXO4i8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important**: The choice of tokenizer is not arbitrary. There are different ways to tokenize text. For example:\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;I didn't even see that.\n",
        "\n",
        "Could be tokenized as\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [I, didn't, even, see, that.]\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [I, did, n't, even, see, that, .]\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [I, didn, ', t, even, see, that, .]\n",
        "\n",
        "And many others. The \"right\" tokenizer greatly depends on what analysis happens next. For instance, you want to use the same tokenizer that was used to train a model if you are applying that model in your data.\n",
        "\n",
        "Without worrying too much about which tokenizer, we will use NLTK's standard version and change it whenever we need."
      ],
      "metadata": {
        "id": "PE-HV70gSYj_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Case-folding\n",
        "\n",
        "For analyzes where case doesn't matter, we can convert all tokens to lower-case\n"
      ],
      "metadata": {
        "id": "eEoIZmHFfhhj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through each subject, transforming all tokens to lower case\n",
        "for subject, subject_data in data.items():\n",
        "    subject_data['all_tokens_lower'] = [token.lower() for token in subject_data['all_tokens']]\n",
        "\n",
        "print(data['104']['all_tokens_lower'][:9])\n"
      ],
      "metadata": {
        "id": "QwqFCdfalh7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Stop word removal\n",
        "\n",
        "For some analysis words such as \"the\", \"and\", \"a\", etc. are not informative. We can use nltk's stopword data base and remove all the stop words in the statements."
      ],
      "metadata": {
        "id": "9JNFUkyyfl_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the stopwords corpus\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download the list of stop words\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Store the list of stop words in the object stop_words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Loop through each subject, removing all stop words\n",
        "for subject, subject_data in data.items():\n",
        "    subject_data['all_tokens_no_stops'] = [token for token in subject_data['all_tokens_lower']\n",
        "                                           if token not in stop_words]\n",
        "\n",
        "print(data['104']['all_tokens_no_stops'][:9])\n"
      ],
      "metadata": {
        "id": "7_CdHtzKk26t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4 Stemming and lemmatization\n",
        "\n",
        "The tokens \"Looking\" \"look\" and \"looked\" all mean the same thing if the analysis is concerned with \"usage of the word look\".\n",
        "\n",
        "One way to accomplish this is through stemming: reducing the word to its stem.\n",
        "\n",
        "A more robust way to do this is to reduce the word to its lemma. In short, stemming is simply cutting the word following certain rules, while lemma uses a wider set of rules to arrive at a word's meaningful base form. For instance:\n",
        "\n",
        "* Stemming \"Caring\" and \"Cared\" might lead to \"Car\"\n",
        "* Lemmatizing \"Caring\" and \"Care\" will produce \"Care\"\n",
        "\n",
        "We will keep a copy of our lemmatized tokens"
      ],
      "metadata": {
        "id": "kUUezLmDfnAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import nltk's lemmatizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Initialize WordNet lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "for subject, subject_data in data.items():\n",
        "      subject_data['all_tokens_lemmatized'] = [lemmatizer.lemmatize(token)\n",
        "                                               for token in subject_data['all_tokens_no_stops']]\n",
        "\n",
        "\n",
        "print(data['104']['all_tokens_lemmatized'][:9])"
      ],
      "metadata": {
        "id": "EsIGxVHS1LTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.5 Removing punctuation\n",
        "\n",
        "For basic analysis such as frequency of words, punctuation might not be relevant."
      ],
      "metadata": {
        "id": "bt8eMqLV8wUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "for subject, subject_data in data.items():\n",
        "  subject_data['all_tokens_clean'] = [token for token in subject_data['all_tokens_lemmatized']\n",
        "                                      if token not in string.punctuation]\n",
        "\n",
        "print(data['104']['all_tokens_clean'][:9])"
      ],
      "metadata": {
        "id": "UTexOHNP_EFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some tokens are still not meaningful such as `'` or `1`. But we can deal with them later :)\n"
      ],
      "metadata": {
        "id": "R7jYcMuAAkDn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.6 Sentence tokenization\n",
        "\n",
        "We can (and we certainly will) perform analysis at the level of individual words. However, individual sentences are another natural way to \"chunk\" the text. Individual sentences, rather than individual word tokens, can be more informative when context is important. This is certainly true for clustering and classification.\n",
        "\n",
        "Luckily, nltk provides a `sent_tokenizer()` function"
      ],
      "metadata": {
        "id": "f7WGLGuhHi1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for subject, subject_data in data.items():\n",
        "    sentence_tokens = []\n",
        "\n",
        "    for sentence in subject_data[\"statements\"]:\n",
        "        sentence_tokens.extend(nltk.sent_tokenize(sentence))\n",
        "    subject_data[\"sentence_tokens\"] = sentence_tokens\n",
        "\n",
        "print(data['104']['sentence_tokens'][:9])\n"
      ],
      "metadata": {
        "id": "ihE-6bnnH-Jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, each token is an individual sentence.\n",
        "\n",
        "We can take advantage of nesting lists and dictionaries and create yet a new token: individual words within individual sentences. To do this, simply create all `word_tokens` for each `sentence_tokens`"
      ],
      "metadata": {
        "id": "UcySMvxBITFy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for subject, subject_data in data.items():\n",
        "    word_tokens = []\n",
        "\n",
        "    for sentence_token in subject_data[\"sentence_tokens\"]:\n",
        "        word_tokens.append(nltk.word_tokenize(sentence_token))\n",
        "\n",
        "    subject_data[\"word_tokens\"] = word_tokens\n",
        "\n",
        "print(data['104']['word_tokens'][:9])\n"
      ],
      "metadata": {
        "id": "WDRrY4ASIPpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "ℹ️ We have performed sequential operations during the pre-processing stage, and this is often the case. The steps and the details of each step (for instance, what tokenizer to use, or whether to remove stop words) depends largely on the analysis that will follow.\n",
        "\n",
        "These sequential operations are called **pipelines** in NLP. During actual analysis, we will determine the specific pipeline for a project and perform all steps within a single for loop.\n",
        "\n",
        "As such, this section provides an overview of how all analyses will start. Each analysis starts with a pre-processing block using a combination of some or all of the steps delineated here.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "gm8iJflwB2Zz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Feature extraction\n",
        "\n",
        "Computers being unable to understand words might be the fundamental challenge in NLP.\n",
        "\n",
        "Before analysis, we will try to come up with ways to find representations for the data so that\n",
        "\n",
        "1. The computer can interpret and make calculations with the representation\n",
        "2. The representation carries some meaning\n",
        "\n",
        "Feature extraction is arguably the most challenging and important part of any NLP (in fact, of all machine learning) projects. **Feature engineering** is the discipline that focuses on this particular challenge.\n",
        "\n",
        "We will use some commonly used feature extraction methods here. However, a solid project will often rely on new features custom for that project."
      ],
      "metadata": {
        "id": "YAqQM1SWfrIL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 POS-tagging\n",
        "\n",
        "One relevant feature we can extract from the text is the part of speech (POS). We can easily include data for the part of speaech using a POS (part-of-speech) tag.\n",
        "\n",
        "We will use nltk's averaged perceptron tagger which is a machine learning algorithm. It was trained on a large labeled database, and we are extending its capacity to generalize to our text. For detailed info on the averaged perceptron tagger, look [here](https://explosion.ai/blog/part-of-speech-pos-tagger-in-python)\n",
        "\n",
        "First, we inspect how the `pos_tag()` output looks like with the example sentence\n"
      ],
      "metadata": {
        "id": "Utval5p1Ogm5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Cu8HKW45McyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the average perceptron tagger\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "example_postag = nltk.pos_tag(sentence_tokens)\n",
        "\n",
        "pprint.pprint(example_postag)"
      ],
      "metadata": {
        "id": "UMx-uto4OKzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is a summary of the POS tags.\n"
      ],
      "metadata": {
        "id": "IyGLzZRUD1IH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![nltk-speech-codes.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "gop6fvRcV0mg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can store the entire POS-tag data for each subject. As always, we will create a new entry in the dictionary for that. We will use the main `all_tokens` and not any of the cleaned versions in this example.\n"
      ],
      "metadata": {
        "id": "8neIgea3FVvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through each subject, adding all the pos tags\n",
        "for subject, subject_data in data.items():\n",
        "    pos_tag = []\n",
        "    for word_token in subject_data[\"word_tokens\"]:\n",
        "        pos_tag.append(nltk.pos_tag(word_token))\n",
        "\n",
        "    subject_data[\"postag\"] = pos_tag\n",
        "\n",
        "\n",
        "print(data['104']['postag'][:9])"
      ],
      "metadata": {
        "id": "z8FjPpFnDxjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the POS-tagger wrongly classified sounds (a verb) as a plural noun. Visual inspection is fundamental at every stage.\n",
        "\n",
        "Carefully organizing your pipeline will maximize the likelihood of good labeled data. For every algorithm, look at what steps were used in the pipeline of the training data used by the algorithm.\n",
        "\n",
        "In the context of feature extraction, we can assign numbers to different POS-tags, and we can feed that information to the computer. So now each subject's sentence is a string of numbers corresponding to the part-of-speech. We could use this data to analyze sentence structure, look at modal verbs, etc."
      ],
      "metadata": {
        "id": "0mBVyd6VFX_l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Vectorization\n",
        "\n",
        "\n",
        "Another way to represent language data is through a vector. Each vector is an array of numbers. Each word (or sentence, or whatever unit of analysis) can be represented by a vector in n dimensions, where n is the number of features."
      ],
      "metadata": {
        "id": "QpsW-8b4G4i5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Theoretical example\n",
        "For instance, let's say we have two features:\n",
        "1. whether a token is a verb or not (represented by 1 or 0)\n",
        "2. whether that token represents something related to sensation (on an arbitrary scale from 0 to 1, where 0 means not at all related to sensation, and 1 is an explicit sensory word).\n",
        "\n",
        "Now, each subject's tokens are represented by a two-dimensional vector. Let's look at a theoretical example:"
      ],
      "metadata": {
        "id": "gb5dt1VgcCip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hypothetical_vectorization = {\n",
        "    501: {\n",
        "        'sentences': [\"I see water\", \"I smell bugs\"],\n",
        "        'vectors': [[[0, 0.5], [1, 0.97], [0, 0.1]],\n",
        "                    [[0, 0.5], [1, 0.99], [0, 0.5]]]\n",
        "    },\n",
        "    502: {\n",
        "        'sentences': [\"Cars are fast\", \"Ball is round\"],\n",
        "        'vectors': [[[0, 0.2], [1, 0.1], [0, 0.3]],\n",
        "                    [[0, 0.4], [1, 0.1], [0, 0.8]]]\n",
        "    }\n",
        "}\n",
        "\n",
        "pprint.pprint(hypothetical_vectorization)"
      ],
      "metadata": {
        "id": "87urssqBOCI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The hypothetical algorithm ranked verbs correctly. It assigned a high sensory score to words \"see\" and \"smell\", a somewhat high score to \"round\" and \"bugs\" and a low score to \"cars\" and \"ball\". Let's pretend this all makes sense.\n",
        "\n",
        "How are vectors useful?\n",
        "\n",
        "First, vectors can be represented in n-dimensional space. In other words, now each token is represented in space. We can, for example:\n",
        "\n",
        "1. Estimate a sentence's location by the average position of its tokens\n",
        "2. Estimate similarity between sentences\n",
        "3. Estimate how \"sensory\" someone is based on how far to the sensory side of the scale their vectors tend to lie\n",
        "\n",
        "In our convenient example, we can easily visualize the vectors in two dimensions"
      ],
      "metadata": {
        "id": "_1IOGXB2QE-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Iterate at each sentence key: value pair\n",
        "for key, value in hypothetical_vectorization.items():\n",
        "    sentences = value['sentences']\n",
        "    vectors = value['vectors']\n",
        "\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        for j, vector in enumerate(vectors[i]):\n",
        "            if key == 501:\n",
        "                ax.plot(vector[0], vector[1], 'o', label=f'{sentence.split()[j]}: {vector}', color='red')\n",
        "            elif key == 502:\n",
        "                ax.plot(vector[0], vector[1], 'o', label=f'{sentence.split()[j]}: {vector}', color='blue')\n",
        "\n",
        "ax.set_xlabel('Verb')\n",
        "ax.set_ylabel('Sensory')\n",
        "ax.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QnKdgzFTRD_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this simple example, we can get a sense of what words are similar, create a general profile for each sentence, for each subject based on its average position, cluster words/sentences together or even classify a new word based on its features.\n",
        "\n",
        "Evidently, real examples contain many more than two features and can't be easily visualized. But the underlying principles are the same: we can ask questions about categories based on where tokens are in n-dimensions. We can also calculate distance between tokens, sentences or subjects."
      ],
      "metadata": {
        "id": "RbieOlQ3QFFD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Real example: Bag of Words\n",
        "\n",
        "We will use a more efficient way to create features than inventing (and giving values to) our own.\n",
        "\n",
        "The most basic vectorizer is a count vectorizer. It takes each word in the corpus as a feature. Then it counts how many times each word is said in a sentence.\n",
        "\n",
        "The vector representation is a n-sized vector where n is the number of unique words on the entire document.\n",
        "\n",
        "Let's vectorize our real data. First, remember all the keys we added so far with the `.keys()` method."
      ],
      "metadata": {
        "id": "KKeH5aKLSgZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(data['104'].keys())"
      ],
      "metadata": {
        "id": "FGewEY16Tj88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will vectorize the `all_tokens_clean` list.\n",
        "\n",
        "1. Write a corpus consisting of all unique tokens\n",
        "2. Use the `CountVectorizer` module to get counts for each subject\n",
        "3. Construct a BoW representation where each row is a subject and each column is a unique token. Each cell `n, m` is the count of how many times subject `n` said the word `m`.\n",
        "4. Inspect the data with `pandas.head()` command, which displays the first few rows\n",
        "\n",
        "---\n",
        "ℹ️ Pandas is a widely used package used to work with data frames. Pandas data frames work similarly to excel sheets, with data organized in rows and columns.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "kwc_V8kcTy5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Prepare a corpus using the tokens for each subject, and keep track of the IDs\n",
        "ids = []\n",
        "corpus = []\n",
        "for subject, subject_data in data.items():\n",
        "    ids.append(subject)\n",
        "    corpus.append(' '.join(subject_data['all_tokens_clean']))\n",
        "\n",
        "# Transform the corpus into a bag of words\n",
        "BoW = vectorizer.fit_transform(corpus)\n",
        "\n",
        "# Convert the matrix to a DataFrame and set row (index) names to subjectIDs\n",
        "BoW = pd.DataFrame(BoW.toarray(),\n",
        "                   index=ids,\n",
        "                   columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "\n",
        "BoW.head()"
      ],
      "metadata": {
        "id": "jPSrKAwI1UsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Analysis!\n",
        "\n",
        "Now to the fun part. We can use the features we extracted to learn something from the data.\n",
        "\n",
        "Let's start getting some basic information:\n",
        "\n",
        "1) How many tokens did each subject say?\n"
      ],
      "metadata": {
        "id": "Qmu9Yt7fduDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "verbose = {}\n",
        "\n",
        "for subject, subject_data in data.items():\n",
        "    # Create a new dictionary for each subject\n",
        "    verbose[subject] = {\n",
        "        'token_length': len(subject_data['all_tokens']),\n",
        "    }\n",
        "\n",
        "pprint.pprint(verbose)"
      ],
      "metadata": {
        "id": "u6W0d_1od_rs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) How about the frequency of verbs for each subject?"
      ],
      "metadata": {
        "id": "p7FdzhR0gIaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for subject, subject_data in data.items():\n",
        "    # Initialize a counter\n",
        "    verb_count = 0\n",
        "    # Iterate over each sentence\n",
        "    for sentence in subject_data['postag']:\n",
        "        # Iterate over each pair (token, POS_tag)\n",
        "        for pos_tuple in sentence:\n",
        "            # Count if the token is a verb\n",
        "            if pos_tuple[1] == 'VB':\n",
        "                verb_count += 1\n",
        "\n",
        "    # Create an output with all the data\n",
        "    verbose[subject] = {\n",
        "        'token_length': len(subject_data['all_tokens']),\n",
        "        'verb_count': verb_count,\n",
        "        'verb_fraction': verb_count / len(subject_data['all_tokens'])\n",
        "    }\n",
        "\n",
        "pprint.pprint(verbose)"
      ],
      "metadata": {
        "id": "lcdu9i4AgfBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is useful to know how to convert from a dictionary to a pandas data frame"
      ],
      "metadata": {
        "id": "N_XYcU8HitZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "verbose = pd.DataFrame(verbose).T\n",
        "verbose.head()"
      ],
      "metadata": {
        "id": "mYU350CqisrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use a boxplot to investigate the frequency of verbs and if anyone tends to use them too often"
      ],
      "metadata": {
        "id": "QdtgfUJTjZZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Boxplot\n",
        "sns.boxplot(y='verb_fraction', data=verbose, color='lightblue', width=0.3)\n",
        "\n",
        "# Add text at each data point\n",
        "for i in range(verbose.shape[0]):\n",
        "    plt.text(x=0, y=verbose['verb_fraction'].iloc[i],\n",
        "             s=verbose.index[i], color='black', size=8)\n",
        "\n",
        "plt.title('Boxplot with Data Points as Text')\n",
        "plt.xlabel('Subjects')\n",
        "plt.ylabel('Verb Fraction')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6q54r9jRjYUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "During the actual analysis, we might want to exclude the interviewer :)\n",
        "\n",
        "3. How about the frequency of words? That's easy once we have a BoW object"
      ],
      "metadata": {
        "id": "8TNlbVqditfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a ordered BoW object, summing across all subjects\n",
        "overall_frequency = BoW.sum().sort_values(ascending=False)\n",
        "\n",
        "# Get the most frequent 20 words\n",
        "print(overall_frequency[:20])\n",
        "\n",
        "# Get the least frequent 10 words\n",
        "print(overall_frequency[-10:])"
      ],
      "metadata": {
        "id": "kaL5NrrGavUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objects 217 and 218 appear to be particularly popular!\n",
        "\n",
        "4. Distribution of object references per person"
      ],
      "metadata": {
        "id": "YY25ZmZblOGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Create an empty dictionary to hold the frequency of objects\n",
        "object_frequencies = {}\n",
        "\n",
        "for subject, subject_data in data.items():\n",
        "\n",
        "  object_counter = Counter(subject_data['objects'])\n",
        "  total = sum(object_counter.values())\n",
        "  object_proportions = {k: v/total for k, v in object_counter.items()}\n",
        "\n",
        "  object_frequencies[subject] = {\n",
        "      'object_frequency': object_counter.most_common(),\n",
        "      'object_proportion': sorted(object_proportions.items(), key=lambda item: item[1], reverse=True)\n",
        "  }\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame([\n",
        "    {\n",
        "        'subject': subject,\n",
        "        'object_proportion': subject_data['object_proportion']\n",
        "    }\n",
        "    for subject, subject_data in object_frequencies.items()\n",
        "])\n",
        "\n",
        "import pprint\n",
        "pprint.pprint(object_frequencies)\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhQJg-PNrDuH",
        "outputId": "21ee9215-47ad-4d5b-ddc6-a1794a07706c"
      },
      "execution_count": 315,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'000': {'object_frequency': [(201, 1),\n",
            "                              (203, 1),\n",
            "                              (205, 1),\n",
            "                              (206, 1),\n",
            "                              (207, 1),\n",
            "                              (208, 1)],\n",
            "         'object_proportion': [(201, 0.16666666666666666),\n",
            "                               (203, 0.16666666666666666),\n",
            "                               (205, 0.16666666666666666),\n",
            "                               (206, 0.16666666666666666),\n",
            "                               (207, 0.16666666666666666),\n",
            "                               (208, 0.16666666666666666)]},\n",
            " '104': {'object_frequency': [(217, 10),\n",
            "                              (202, 8),\n",
            "                              (222, 8),\n",
            "                              (205, 7),\n",
            "                              (206, 7),\n",
            "                              (208, 7),\n",
            "                              (218, 7),\n",
            "                              (221, 7),\n",
            "                              (201, 6),\n",
            "                              (223, 6),\n",
            "                              (220, 5),\n",
            "                              (224, 5),\n",
            "                              (204, 4),\n",
            "                              (212, 4),\n",
            "                              (219, 4),\n",
            "                              (203, 3),\n",
            "                              (209, 3),\n",
            "                              (211, 3),\n",
            "                              (207, 2),\n",
            "                              (210, 1)],\n",
            "         'object_proportion': [(217, 0.09345794392523364),\n",
            "                               (202, 0.07476635514018691),\n",
            "                               (222, 0.07476635514018691),\n",
            "                               (205, 0.06542056074766354),\n",
            "                               (206, 0.06542056074766354),\n",
            "                               (208, 0.06542056074766354),\n",
            "                               (218, 0.06542056074766354),\n",
            "                               (221, 0.06542056074766354),\n",
            "                               (201, 0.056074766355140186),\n",
            "                               (223, 0.056074766355140186),\n",
            "                               (220, 0.04672897196261682),\n",
            "                               (224, 0.04672897196261682),\n",
            "                               (204, 0.037383177570093455),\n",
            "                               (212, 0.037383177570093455),\n",
            "                               (219, 0.037383177570093455),\n",
            "                               (203, 0.028037383177570093),\n",
            "                               (209, 0.028037383177570093),\n",
            "                               (211, 0.028037383177570093),\n",
            "                               (207, 0.018691588785046728),\n",
            "                               (210, 0.009345794392523364)]},\n",
            " '105': {'object_frequency': [(211, 6),\n",
            "                              (216, 5),\n",
            "                              (218, 5),\n",
            "                              (219, 4),\n",
            "                              (212, 3),\n",
            "                              (222, 3),\n",
            "                              (202, 2),\n",
            "                              (204, 2),\n",
            "                              (205, 2),\n",
            "                              (206, 2),\n",
            "                              (208, 2),\n",
            "                              (210, 2),\n",
            "                              (209, 2),\n",
            "                              (220, 2),\n",
            "                              (224, 2),\n",
            "                              (223, 2),\n",
            "                              (221, 2),\n",
            "                              (201, 1),\n",
            "                              (203, 1),\n",
            "                              (207, 1),\n",
            "                              (213, 1),\n",
            "                              (214, 1),\n",
            "                              (215, 1),\n",
            "                              (217, 1)],\n",
            "         'object_proportion': [(211, 0.10909090909090909),\n",
            "                               (216, 0.09090909090909091),\n",
            "                               (218, 0.09090909090909091),\n",
            "                               (219, 0.07272727272727272),\n",
            "                               (212, 0.05454545454545454),\n",
            "                               (222, 0.05454545454545454),\n",
            "                               (202, 0.03636363636363636),\n",
            "                               (204, 0.03636363636363636),\n",
            "                               (205, 0.03636363636363636),\n",
            "                               (206, 0.03636363636363636),\n",
            "                               (208, 0.03636363636363636),\n",
            "                               (210, 0.03636363636363636),\n",
            "                               (209, 0.03636363636363636),\n",
            "                               (220, 0.03636363636363636),\n",
            "                               (224, 0.03636363636363636),\n",
            "                               (223, 0.03636363636363636),\n",
            "                               (221, 0.03636363636363636),\n",
            "                               (201, 0.01818181818181818),\n",
            "                               (203, 0.01818181818181818),\n",
            "                               (207, 0.01818181818181818),\n",
            "                               (213, 0.01818181818181818),\n",
            "                               (214, 0.01818181818181818),\n",
            "                               (215, 0.01818181818181818),\n",
            "                               (217, 0.01818181818181818)]},\n",
            " '106': {'object_frequency': [(218, 8),\n",
            "                              (213, 7),\n",
            "                              (214, 7),\n",
            "                              (207, 6),\n",
            "                              (215, 6),\n",
            "                              (219, 6),\n",
            "                              (217, 6),\n",
            "                              (220, 6),\n",
            "                              (221, 6),\n",
            "                              (222, 6),\n",
            "                              (223, 6),\n",
            "                              (208, 5),\n",
            "                              (205, 5),\n",
            "                              (206, 5),\n",
            "                              (216, 5),\n",
            "                              (224, 5),\n",
            "                              (203, 3),\n",
            "                              (202, 3),\n",
            "                              (201, 3),\n",
            "                              (204, 3),\n",
            "                              (211, 3),\n",
            "                              (210, 3),\n",
            "                              (212, 2),\n",
            "                              (209, 2)],\n",
            "         'object_proportion': [(218, 0.06837606837606838),\n",
            "                               (213, 0.05982905982905983),\n",
            "                               (214, 0.05982905982905983),\n",
            "                               (207, 0.05128205128205128),\n",
            "                               (215, 0.05128205128205128),\n",
            "                               (219, 0.05128205128205128),\n",
            "                               (217, 0.05128205128205128),\n",
            "                               (220, 0.05128205128205128),\n",
            "                               (221, 0.05128205128205128),\n",
            "                               (222, 0.05128205128205128),\n",
            "                               (223, 0.05128205128205128),\n",
            "                               (208, 0.042735042735042736),\n",
            "                               (205, 0.042735042735042736),\n",
            "                               (206, 0.042735042735042736),\n",
            "                               (216, 0.042735042735042736),\n",
            "                               (224, 0.042735042735042736),\n",
            "                               (203, 0.02564102564102564),\n",
            "                               (202, 0.02564102564102564),\n",
            "                               (201, 0.02564102564102564),\n",
            "                               (204, 0.02564102564102564),\n",
            "                               (211, 0.02564102564102564),\n",
            "                               (210, 0.02564102564102564),\n",
            "                               (212, 0.017094017094017096),\n",
            "                               (209, 0.017094017094017096)]},\n",
            " '107': {'object_frequency': [(213, 13),\n",
            "                              (216, 12),\n",
            "                              (214, 11),\n",
            "                              (215, 11),\n",
            "                              (202, 10),\n",
            "                              (218, 10),\n",
            "                              (219, 10),\n",
            "                              (220, 10),\n",
            "                              (203, 9),\n",
            "                              (204, 9),\n",
            "                              (205, 9),\n",
            "                              (206, 9),\n",
            "                              (208, 9),\n",
            "                              (217, 9),\n",
            "                              (224, 9),\n",
            "                              (201, 8),\n",
            "                              (207, 8),\n",
            "                              (211, 8),\n",
            "                              (222, 7),\n",
            "                              (223, 7),\n",
            "                              (209, 6),\n",
            "                              (221, 6),\n",
            "                              (210, 5),\n",
            "                              (212, 5),\n",
            "                              (109, 1),\n",
            "                              (110, 1),\n",
            "                              (111, 1),\n",
            "                              (112, 1)],\n",
            "         'object_proportion': [(213, 0.06074766355140187),\n",
            "                               (216, 0.056074766355140186),\n",
            "                               (214, 0.0514018691588785),\n",
            "                               (215, 0.0514018691588785),\n",
            "                               (202, 0.04672897196261682),\n",
            "                               (218, 0.04672897196261682),\n",
            "                               (219, 0.04672897196261682),\n",
            "                               (220, 0.04672897196261682),\n",
            "                               (203, 0.04205607476635514),\n",
            "                               (204, 0.04205607476635514),\n",
            "                               (205, 0.04205607476635514),\n",
            "                               (206, 0.04205607476635514),\n",
            "                               (208, 0.04205607476635514),\n",
            "                               (217, 0.04205607476635514),\n",
            "                               (224, 0.04205607476635514),\n",
            "                               (201, 0.037383177570093455),\n",
            "                               (207, 0.037383177570093455),\n",
            "                               (211, 0.037383177570093455),\n",
            "                               (222, 0.03271028037383177),\n",
            "                               (223, 0.03271028037383177),\n",
            "                               (209, 0.028037383177570093),\n",
            "                               (221, 0.028037383177570093),\n",
            "                               (210, 0.02336448598130841),\n",
            "                               (212, 0.02336448598130841),\n",
            "                               (109, 0.004672897196261682),\n",
            "                               (110, 0.004672897196261682),\n",
            "                               (111, 0.004672897196261682),\n",
            "                               (112, 0.004672897196261682)]},\n",
            " '108': {'object_frequency': [(223, 6),\n",
            "                              (222, 6),\n",
            "                              (217, 4),\n",
            "                              (204, 3),\n",
            "                              (205, 3),\n",
            "                              (215, 3),\n",
            "                              (218, 3),\n",
            "                              (224, 3),\n",
            "                              (221, 3),\n",
            "                              (201, 2),\n",
            "                              (202, 2),\n",
            "                              (203, 2),\n",
            "                              (206, 2),\n",
            "                              (211, 2),\n",
            "                              (208, 1),\n",
            "                              (207, 1),\n",
            "                              (210, 1),\n",
            "                              (212, 1),\n",
            "                              (209, 1),\n",
            "                              (214, 1),\n",
            "                              (213, 1),\n",
            "                              (216, 1),\n",
            "                              (220, 1),\n",
            "                              (219, 1)],\n",
            "         'object_proportion': [(223, 0.1111111111111111),\n",
            "                               (222, 0.1111111111111111),\n",
            "                               (217, 0.07407407407407407),\n",
            "                               (204, 0.05555555555555555),\n",
            "                               (205, 0.05555555555555555),\n",
            "                               (215, 0.05555555555555555),\n",
            "                               (218, 0.05555555555555555),\n",
            "                               (224, 0.05555555555555555),\n",
            "                               (221, 0.05555555555555555),\n",
            "                               (201, 0.037037037037037035),\n",
            "                               (202, 0.037037037037037035),\n",
            "                               (203, 0.037037037037037035),\n",
            "                               (206, 0.037037037037037035),\n",
            "                               (211, 0.037037037037037035),\n",
            "                               (208, 0.018518518518518517),\n",
            "                               (207, 0.018518518518518517),\n",
            "                               (210, 0.018518518518518517),\n",
            "                               (212, 0.018518518518518517),\n",
            "                               (209, 0.018518518518518517),\n",
            "                               (214, 0.018518518518518517),\n",
            "                               (213, 0.018518518518518517),\n",
            "                               (216, 0.018518518518518517),\n",
            "                               (220, 0.018518518518518517),\n",
            "                               (219, 0.018518518518518517)]},\n",
            " '109': {'object_frequency': [(222, 13),\n",
            "                              (202, 11),\n",
            "                              (204, 10),\n",
            "                              (207, 10),\n",
            "                              (205, 10),\n",
            "                              (206, 10),\n",
            "                              (213, 10),\n",
            "                              (214, 10),\n",
            "                              (221, 10),\n",
            "                              (201, 9),\n",
            "                              (203, 9),\n",
            "                              (217, 9),\n",
            "                              (208, 8),\n",
            "                              (211, 8),\n",
            "                              (209, 8),\n",
            "                              (216, 8),\n",
            "                              (224, 8),\n",
            "                              (210, 7),\n",
            "                              (212, 7),\n",
            "                              (220, 7),\n",
            "                              (218, 7),\n",
            "                              (215, 6),\n",
            "                              (219, 5),\n",
            "                              (223, 5)],\n",
            "         'object_proportion': [(222, 0.06341463414634146),\n",
            "                               (202, 0.05365853658536585),\n",
            "                               (204, 0.04878048780487805),\n",
            "                               (207, 0.04878048780487805),\n",
            "                               (205, 0.04878048780487805),\n",
            "                               (206, 0.04878048780487805),\n",
            "                               (213, 0.04878048780487805),\n",
            "                               (214, 0.04878048780487805),\n",
            "                               (221, 0.04878048780487805),\n",
            "                               (201, 0.04390243902439024),\n",
            "                               (203, 0.04390243902439024),\n",
            "                               (217, 0.04390243902439024),\n",
            "                               (208, 0.03902439024390244),\n",
            "                               (211, 0.03902439024390244),\n",
            "                               (209, 0.03902439024390244),\n",
            "                               (216, 0.03902439024390244),\n",
            "                               (224, 0.03902439024390244),\n",
            "                               (210, 0.03414634146341464),\n",
            "                               (212, 0.03414634146341464),\n",
            "                               (220, 0.03414634146341464),\n",
            "                               (218, 0.03414634146341464),\n",
            "                               (215, 0.02926829268292683),\n",
            "                               (219, 0.024390243902439025),\n",
            "                               (223, 0.024390243902439025)]},\n",
            " '110': {'object_frequency': [(203, 11),\n",
            "                              (217, 11),\n",
            "                              (218, 11),\n",
            "                              (219, 11),\n",
            "                              (206, 10),\n",
            "                              (207, 10),\n",
            "                              (222, 10),\n",
            "                              (201, 9),\n",
            "                              (204, 9),\n",
            "                              (205, 9),\n",
            "                              (220, 8),\n",
            "                              (202, 7),\n",
            "                              (216, 7),\n",
            "                              (221, 7),\n",
            "                              (223, 7),\n",
            "                              (214, 6),\n",
            "                              (213, 6),\n",
            "                              (215, 6),\n",
            "                              (208, 5),\n",
            "                              (211, 5),\n",
            "                              (212, 5),\n",
            "                              (224, 5),\n",
            "                              (209, 4),\n",
            "                              (210, 3)],\n",
            "         'object_proportion': [(203, 0.06043956043956044),\n",
            "                               (217, 0.06043956043956044),\n",
            "                               (218, 0.06043956043956044),\n",
            "                               (219, 0.06043956043956044),\n",
            "                               (206, 0.054945054945054944),\n",
            "                               (207, 0.054945054945054944),\n",
            "                               (222, 0.054945054945054944),\n",
            "                               (201, 0.04945054945054945),\n",
            "                               (204, 0.04945054945054945),\n",
            "                               (205, 0.04945054945054945),\n",
            "                               (220, 0.04395604395604396),\n",
            "                               (202, 0.038461538461538464),\n",
            "                               (216, 0.038461538461538464),\n",
            "                               (221, 0.038461538461538464),\n",
            "                               (223, 0.038461538461538464),\n",
            "                               (214, 0.03296703296703297),\n",
            "                               (213, 0.03296703296703297),\n",
            "                               (215, 0.03296703296703297),\n",
            "                               (208, 0.027472527472527472),\n",
            "                               (211, 0.027472527472527472),\n",
            "                               (212, 0.027472527472527472),\n",
            "                               (224, 0.027472527472527472),\n",
            "                               (209, 0.02197802197802198),\n",
            "                               (210, 0.016483516483516484)]},\n",
            " '111': {'object_frequency': [(223, 9),\n",
            "                              (218, 8),\n",
            "                              (213, 6),\n",
            "                              (215, 6),\n",
            "                              (216, 6),\n",
            "                              (220, 6),\n",
            "                              (222, 6),\n",
            "                              (224, 6),\n",
            "                              (214, 5),\n",
            "                              (217, 5),\n",
            "                              (219, 5),\n",
            "                              (221, 5),\n",
            "                              (201, 4),\n",
            "                              (205, 4),\n",
            "                              (203, 3),\n",
            "                              (202, 3),\n",
            "                              (206, 3),\n",
            "                              (210, 3),\n",
            "                              (209, 3),\n",
            "                              (204, 2),\n",
            "                              (207, 2),\n",
            "                              (208, 2),\n",
            "                              (211, 2),\n",
            "                              (212, 2)],\n",
            "         'object_proportion': [(223, 0.08490566037735849),\n",
            "                               (218, 0.07547169811320754),\n",
            "                               (213, 0.05660377358490566),\n",
            "                               (215, 0.05660377358490566),\n",
            "                               (216, 0.05660377358490566),\n",
            "                               (220, 0.05660377358490566),\n",
            "                               (222, 0.05660377358490566),\n",
            "                               (224, 0.05660377358490566),\n",
            "                               (214, 0.04716981132075472),\n",
            "                               (217, 0.04716981132075472),\n",
            "                               (219, 0.04716981132075472),\n",
            "                               (221, 0.04716981132075472),\n",
            "                               (201, 0.03773584905660377),\n",
            "                               (205, 0.03773584905660377),\n",
            "                               (203, 0.02830188679245283),\n",
            "                               (202, 0.02830188679245283),\n",
            "                               (206, 0.02830188679245283),\n",
            "                               (210, 0.02830188679245283),\n",
            "                               (209, 0.02830188679245283),\n",
            "                               (204, 0.018867924528301886),\n",
            "                               (207, 0.018867924528301886),\n",
            "                               (208, 0.018867924528301886),\n",
            "                               (211, 0.018867924528301886),\n",
            "                               (212, 0.018867924528301886)]},\n",
            " '112': {'object_frequency': [(220, 13),\n",
            "                              (222, 13),\n",
            "                              (217, 12),\n",
            "                              (219, 12),\n",
            "                              (221, 12),\n",
            "                              (218, 11),\n",
            "                              (224, 11),\n",
            "                              (223, 11),\n",
            "                              (214, 10),\n",
            "                              (215, 10),\n",
            "                              (212, 8),\n",
            "                              (201, 7),\n",
            "                              (202, 7),\n",
            "                              (204, 7),\n",
            "                              (206, 7),\n",
            "                              (209, 7),\n",
            "                              (205, 6),\n",
            "                              (207, 6),\n",
            "                              (208, 6),\n",
            "                              (213, 6),\n",
            "                              (216, 6),\n",
            "                              (203, 5),\n",
            "                              (210, 5),\n",
            "                              (211, 4)],\n",
            "         'object_proportion': [(220, 0.06435643564356436),\n",
            "                               (222, 0.06435643564356436),\n",
            "                               (217, 0.0594059405940594),\n",
            "                               (219, 0.0594059405940594),\n",
            "                               (221, 0.0594059405940594),\n",
            "                               (218, 0.054455445544554455),\n",
            "                               (224, 0.054455445544554455),\n",
            "                               (223, 0.054455445544554455),\n",
            "                               (214, 0.04950495049504951),\n",
            "                               (215, 0.04950495049504951),\n",
            "                               (212, 0.039603960396039604),\n",
            "                               (201, 0.034653465346534656),\n",
            "                               (202, 0.034653465346534656),\n",
            "                               (204, 0.034653465346534656),\n",
            "                               (206, 0.034653465346534656),\n",
            "                               (209, 0.034653465346534656),\n",
            "                               (205, 0.0297029702970297),\n",
            "                               (207, 0.0297029702970297),\n",
            "                               (208, 0.0297029702970297),\n",
            "                               (213, 0.0297029702970297),\n",
            "                               (216, 0.0297029702970297),\n",
            "                               (203, 0.024752475247524754),\n",
            "                               (210, 0.024752475247524754),\n",
            "                               (211, 0.019801980198019802)]},\n",
            " '113': {'object_frequency': [(203, 7),\n",
            "                              (205, 7),\n",
            "                              (207, 7),\n",
            "                              (201, 6),\n",
            "                              (206, 6),\n",
            "                              (202, 5),\n",
            "                              (204, 5),\n",
            "                              (208, 4),\n",
            "                              (212, 4),\n",
            "                              (211, 4),\n",
            "                              (210, 2),\n",
            "                              (209, 1),\n",
            "                              (213, 1),\n",
            "                              (214, 1),\n",
            "                              (215, 1),\n",
            "                              (216, 1),\n",
            "                              (217, 1),\n",
            "                              (221, 1)],\n",
            "         'object_proportion': [(203, 0.109375),\n",
            "                               (205, 0.109375),\n",
            "                               (207, 0.109375),\n",
            "                               (201, 0.09375),\n",
            "                               (206, 0.09375),\n",
            "                               (202, 0.078125),\n",
            "                               (204, 0.078125),\n",
            "                               (208, 0.0625),\n",
            "                               (212, 0.0625),\n",
            "                               (211, 0.0625),\n",
            "                               (210, 0.03125),\n",
            "                               (209, 0.015625),\n",
            "                               (213, 0.015625),\n",
            "                               (214, 0.015625),\n",
            "                               (215, 0.015625),\n",
            "                               (216, 0.015625),\n",
            "                               (217, 0.015625),\n",
            "                               (221, 0.015625)]},\n",
            " '114': {'object_frequency': [(215, 4),\n",
            "                              (216, 4),\n",
            "                              (201, 3),\n",
            "                              (204, 3),\n",
            "                              (219, 3),\n",
            "                              (221, 3),\n",
            "                              (202, 2),\n",
            "                              (203, 2),\n",
            "                              (207, 2),\n",
            "                              (206, 2),\n",
            "                              (213, 2),\n",
            "                              (214, 2),\n",
            "                              (223, 2),\n",
            "                              (224, 2),\n",
            "                              (217, 1),\n",
            "                              (218, 1),\n",
            "                              (220, 1),\n",
            "                              (222, 1),\n",
            "                              (209, 1),\n",
            "                              (210, 1),\n",
            "                              (211, 1),\n",
            "                              (212, 1),\n",
            "                              (205, 1),\n",
            "                              (208, 1)],\n",
            "         'object_proportion': [(215, 0.08695652173913043),\n",
            "                               (216, 0.08695652173913043),\n",
            "                               (201, 0.06521739130434782),\n",
            "                               (204, 0.06521739130434782),\n",
            "                               (219, 0.06521739130434782),\n",
            "                               (221, 0.06521739130434782),\n",
            "                               (202, 0.043478260869565216),\n",
            "                               (203, 0.043478260869565216),\n",
            "                               (207, 0.043478260869565216),\n",
            "                               (206, 0.043478260869565216),\n",
            "                               (213, 0.043478260869565216),\n",
            "                               (214, 0.043478260869565216),\n",
            "                               (223, 0.043478260869565216),\n",
            "                               (224, 0.043478260869565216),\n",
            "                               (217, 0.021739130434782608),\n",
            "                               (218, 0.021739130434782608),\n",
            "                               (220, 0.021739130434782608),\n",
            "                               (222, 0.021739130434782608),\n",
            "                               (209, 0.021739130434782608),\n",
            "                               (210, 0.021739130434782608),\n",
            "                               (211, 0.021739130434782608),\n",
            "                               (212, 0.021739130434782608),\n",
            "                               (205, 0.021739130434782608),\n",
            "                               (208, 0.021739130434782608)]},\n",
            " '115': {'object_frequency': [(217, 10),\n",
            "                              (220, 10),\n",
            "                              (208, 8),\n",
            "                              (201, 7),\n",
            "                              (213, 7),\n",
            "                              (214, 7),\n",
            "                              (202, 6),\n",
            "                              (215, 6),\n",
            "                              (218, 6),\n",
            "                              (219, 6),\n",
            "                              (204, 4),\n",
            "                              (203, 4),\n",
            "                              (216, 4),\n",
            "                              (205, 3),\n",
            "                              (206, 3),\n",
            "                              (207, 3),\n",
            "                              (212, 2),\n",
            "                              (210, 2),\n",
            "                              (211, 2),\n",
            "                              (209, 1),\n",
            "                              (221, 1),\n",
            "                              (222, 1),\n",
            "                              (223, 1),\n",
            "                              (224, 1)],\n",
            "         'object_proportion': [(217, 0.09523809523809523),\n",
            "                               (220, 0.09523809523809523),\n",
            "                               (208, 0.0761904761904762),\n",
            "                               (201, 0.06666666666666667),\n",
            "                               (213, 0.06666666666666667),\n",
            "                               (214, 0.06666666666666667),\n",
            "                               (202, 0.05714285714285714),\n",
            "                               (215, 0.05714285714285714),\n",
            "                               (218, 0.05714285714285714),\n",
            "                               (219, 0.05714285714285714),\n",
            "                               (204, 0.0380952380952381),\n",
            "                               (203, 0.0380952380952381),\n",
            "                               (216, 0.0380952380952381),\n",
            "                               (205, 0.02857142857142857),\n",
            "                               (206, 0.02857142857142857),\n",
            "                               (207, 0.02857142857142857),\n",
            "                               (212, 0.01904761904761905),\n",
            "                               (210, 0.01904761904761905),\n",
            "                               (211, 0.01904761904761905),\n",
            "                               (209, 0.009523809523809525),\n",
            "                               (221, 0.009523809523809525),\n",
            "                               (222, 0.009523809523809525),\n",
            "                               (223, 0.009523809523809525),\n",
            "                               (224, 0.009523809523809525)]},\n",
            " '116': {'object_frequency': [(207, 8),\n",
            "                              (211, 8),\n",
            "                              (205, 7),\n",
            "                              (208, 7),\n",
            "                              (206, 6),\n",
            "                              (209, 6),\n",
            "                              (212, 6),\n",
            "                              (220, 6),\n",
            "                              (210, 5),\n",
            "                              (214, 5),\n",
            "                              (217, 5),\n",
            "                              (202, 4),\n",
            "                              (213, 4),\n",
            "                              (215, 4),\n",
            "                              (216, 4),\n",
            "                              (219, 4),\n",
            "                              (201, 3),\n",
            "                              (203, 3),\n",
            "                              (204, 3),\n",
            "                              (221, 3),\n",
            "                              (218, 2),\n",
            "                              (223, 1)],\n",
            "         'object_proportion': [(207, 0.07692307692307693),\n",
            "                               (211, 0.07692307692307693),\n",
            "                               (205, 0.0673076923076923),\n",
            "                               (208, 0.0673076923076923),\n",
            "                               (206, 0.057692307692307696),\n",
            "                               (209, 0.057692307692307696),\n",
            "                               (212, 0.057692307692307696),\n",
            "                               (220, 0.057692307692307696),\n",
            "                               (210, 0.04807692307692308),\n",
            "                               (214, 0.04807692307692308),\n",
            "                               (217, 0.04807692307692308),\n",
            "                               (202, 0.038461538461538464),\n",
            "                               (213, 0.038461538461538464),\n",
            "                               (215, 0.038461538461538464),\n",
            "                               (216, 0.038461538461538464),\n",
            "                               (219, 0.038461538461538464),\n",
            "                               (201, 0.028846153846153848),\n",
            "                               (203, 0.028846153846153848),\n",
            "                               (204, 0.028846153846153848),\n",
            "                               (221, 0.028846153846153848),\n",
            "                               (218, 0.019230769230769232),\n",
            "                               (223, 0.009615384615384616)]},\n",
            " '117': {'object_frequency': [(219, 16),\n",
            "                              (218, 15),\n",
            "                              (217, 14),\n",
            "                              (220, 14),\n",
            "                              (207, 11),\n",
            "                              (211, 11),\n",
            "                              (210, 10),\n",
            "                              (212, 9),\n",
            "                              (209, 8),\n",
            "                              (203, 7),\n",
            "                              (208, 7),\n",
            "                              (201, 6),\n",
            "                              (205, 5),\n",
            "                              (206, 5),\n",
            "                              (213, 5),\n",
            "                              (202, 4),\n",
            "                              (204, 4),\n",
            "                              (221, 3),\n",
            "                              (215, 2),\n",
            "                              (216, 2),\n",
            "                              (222, 1),\n",
            "                              (223, 1),\n",
            "                              (224, 1),\n",
            "                              (214, 1)],\n",
            "         'object_proportion': [(219, 0.09876543209876543),\n",
            "                               (218, 0.09259259259259259),\n",
            "                               (217, 0.08641975308641975),\n",
            "                               (220, 0.08641975308641975),\n",
            "                               (207, 0.06790123456790123),\n",
            "                               (211, 0.06790123456790123),\n",
            "                               (210, 0.06172839506172839),\n",
            "                               (212, 0.05555555555555555),\n",
            "                               (209, 0.04938271604938271),\n",
            "                               (203, 0.043209876543209874),\n",
            "                               (208, 0.043209876543209874),\n",
            "                               (201, 0.037037037037037035),\n",
            "                               (205, 0.030864197530864196),\n",
            "                               (206, 0.030864197530864196),\n",
            "                               (213, 0.030864197530864196),\n",
            "                               (202, 0.024691358024691357),\n",
            "                               (204, 0.024691358024691357),\n",
            "                               (221, 0.018518518518518517),\n",
            "                               (215, 0.012345679012345678),\n",
            "                               (216, 0.012345679012345678),\n",
            "                               (222, 0.006172839506172839),\n",
            "                               (223, 0.006172839506172839),\n",
            "                               (224, 0.006172839506172839),\n",
            "                               (214, 0.006172839506172839)]}}\n",
            "  subject                                  object_proportion\n",
            "0     000  [(201, 0.16666666666666666), (203, 0.166666666...\n",
            "1     104  [(217, 0.09345794392523364), (202, 0.074766355...\n",
            "2     105  [(211, 0.10909090909090909), (216, 0.090909090...\n",
            "3     106  [(218, 0.06837606837606838), (213, 0.059829059...\n",
            "4     107  [(213, 0.06074766355140187), (216, 0.056074766...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. How about the most frequent words per person?"
      ],
      "metadata": {
        "id": "m5mTZAAarFim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) Calculate the ordered frequency for each row in X\n",
        "individual_frequencies = {}\n",
        "for subject in BoW.index:\n",
        "    sorted_freq = BoW.loc[subject].sort_values(ascending=False)\n",
        "    individual_frequencies[subject] = sorted_freq\n",
        "\n",
        "# Display the top 5 words for each subject\n",
        "for subject, freq in individual_frequencies.items():\n",
        "    print({subject})\n",
        "    print(freq[:5])"
      ],
      "metadata": {
        "id": "iU46MWMNbYDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "\n",
        "These steps cover the initial steps to most language processing analyses. To recap, here's a summary of all the steps. While the order presented here corresponds to implementation, the order is shifted during planning:\n",
        "\n",
        "1. Determine what features are relevant for the analyses. The features should be numerical representation of the data, and should be informative to the specific goals of the analysis.\n",
        "2. Create a pre-processing pipeline, including all relevant transformations. This should happen on paper first.\n",
        "  * The pipeline should be decided based on the goal of the analyses\n",
        "  * The models used also dictate what type of pre-processing is required\n",
        "  * Realistically, each project will have its own pipeline. Some steps will be common, while others specific to a project.\n",
        "  * Sometimes, a project may require a custom pre-processing stage.\n",
        "\n",
        "\n",
        "Only at this stage we can start to write code\n",
        "\n",
        "3. Clean the text, paying particular attention to patterns we want to exclude (or make sure we include) based on the goal of our analysis.\n",
        "\n",
        "\n",
        "3. Once the pipeline has been established, we can implement on the cleaned dataset.\n",
        "  * At this stage, visual inspection is the best way to make sure everything has been processed as intended\n",
        "  * It is useful to include some check blocks before starting feature extraction, such as counting how many times the character `.` appears, after attempting to remove it.\n",
        "\n",
        "4. Extract the features from the text.\n",
        "  * This may be done using common approaches such as POS-tagging or BoW, or through custom features\n",
        "  * Often relevant features from a project can be obtained from other commonly used features (such as the feature \"frequency of verbs\" from tokenization and POS-tags)\n",
        "\n",
        "5. Answer the initial questions through analysis of the vectorized texts\n",
        "  * Sometimes interpretability may be difficult. In general, the more information behind a vectorization step, the less interpretable it becomes. In such cases, we will rely on metrics such as distance, clusters or categories without actually visualizing the vectors."
      ],
      "metadata": {
        "id": "5fD7xodH7t-2"
      }
    }
  ]
}